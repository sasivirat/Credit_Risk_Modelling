{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xwh_hbwrqhYP"
      },
      "source": [
        "#Credit Risk Modeling | Part 1: Preprocessing Data\n",
        "\n",
        "<img src='https://youtrading.com/fr/wp-content/uploads/2022/10/GettyImages-1324277066.jpg'>\n",
        "\n",
        "Credit risk modeling is important for financial institutions. It represents the risk of a borrower not being able to pay back the loan amount, credit card or other types of loans. In some cases, borrowers can pay partial of the debt amount; therefore, the principal amount and interest amount are not paid. Both statistics and machine learning techniques play an important role in credit risk modeling. Some core skills include handling big data and advanced statistical modeling. \n",
        "\n",
        "**Terms ‚ö†Ô∏è**\n",
        "\n",
        "There are two types of Internal Rating Based (IRB) approaches which are Foundation IRB and Advanced IRB.  \n",
        "**Foundation IRB**  \n",
        "PD is estimated internally by the bank while LGD and EAD are prescribed by regulator.  \n",
        "**Advanced IRB**  \n",
        "PD, LGD, and EAD can be estimated internally by the bank itself.\n",
        "\n",
        "*  PD: probability of default in logistic regression  \n",
        "Probability of default means the likelihood that a borrower will default on debt (credit card, mortgage or non-mortgage loan) over a one-year period. In simple words, it returns the expected probability of customers fail to repay the loan. Probability is expressed in the form of percentage, lies between 0% and 100%. Higher the probability, higher the chance of default.  \n",
        "*  LGD: Loss given default in beta regression model   \n",
        "It means how much of the amount outstanding we expect to lose. It is a proportion of the total exposure when borrower defaults. It is calculated by (1 - Recovery Rate).  \n",
        "*  EAD: exposure at default in beta regression model  \n",
        "It means how much should we expect the amount outstanding to be in the case of default. It is the amount that the borrower has to pay the bank at the time of default.  \n",
        "\n",
        "We use PD model to create score cards to accept or reject one's demand of credit risk.\n",
        "\n",
        "There are three models to use for bank management\n",
        "*  Exposure Lose, EL = PD x LGD x EAD\n",
        "\n",
        "There are two types of credit risk modeling: \n",
        "1.  Application model.   \n",
        "ÔÉ∞\tWhether to grant a loan or not. What interest rate  \n",
        "ÔÉ∞\tRisk based pricing, higher the risk higher the interest  \n",
        "2.  Behaviour model  \n",
        "ÔÉ∞\tWhether to lend more money to existing borrower. Application.   \n",
        "ÔÉ∞\tStatistical models for estimating credit risk. Represented in a simplified way. Score card. Probability of default model. PD model in a simpler way.   \n",
        "\n",
        "**Dataset ‚ñ∂**\n",
        "\n",
        "The dataset contains more than 800,000 consumer loans issued from 2007 to 2015 by Lending Club. It is a large US peer-to-peer lending company. There are different versions of this dataset online and we take a version available on kaggle.com on (link)[https://www.kaggle.com/wendykan/lending-club-loan-data/version/1} . It should be noted that are discrete and continous columns that should be preprocessed accordingly.\n",
        "\n",
        "We assume a scenario where data from 2007 to 2014 are available at the moment of building initial Expected Loss models, and other part of data of 2015 will become available from the applications later on. Therefore, the data is divided into two periods: (i) data from 2007 to 2014 and (ii) data in 2015.\n",
        "\n",
        "Later, we investigate whether the former Probability of Default (PD) model built with the 2015 data have similar characteristics with the applications we used to build the initial PD model.\n",
        "\n",
        "**Target üéØ** \n",
        "\n",
        "One of the prominent bank is asked us to build a credit risk model by using Loan Data to provide them a scorecard to use in their daily procedures as well a pipeline to calculate exposure loss. \n",
        "\n",
        "Here is a step-by-step instruction obtained as also in compliance with the Basel II requirements: \n",
        "\n",
        "**In Notebook L01** (this notebook)   \n",
        "1-  Preprocessing - Converting columns into dummy variables by fine and coarse classing \n",
        "  \n",
        "**In Notebook L02**  \n",
        "2-  Calculate the PD model with logistic regression  \n",
        "2-  Based on PD model, provide a practical scorecard in csv format  \n",
        "    \n",
        "**In Notebook L03**   \n",
        "3-  Construct LGD model with beta regression  \n",
        "4-  Build EAD model with beta regression  \n",
        "5-  Calculate the exposure loss after obtaining all models  \n",
        "  \n",
        "  \n",
        "**In Notebook L04**  \n",
        "6-  Check the models if they are still doing good with the recent credit risk modeling.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRF4o5oDWICv"
      },
      "source": [
        "# 1 Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j6DqIieWIC4"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYhCfJwQczOC",
        "outputId": "57b6b1ca-8043-44e9-937c-c10d18564861"
      },
      "outputs": [],
      "source": [
        "#installing gdown package to download dataset stored in G Drive\n",
        "!pip install gdown\n",
        "# to upgrade\n",
        "!pip install --upgrade gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KtnFrE1fWIC5"
      },
      "outputs": [],
      "source": [
        "#data handling libs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#lib to download the g-drive data\n",
        "import gdown\n",
        "\n",
        "#sklearn libs\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#data viz\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "#importing custom-made functions\n",
        "import sys #importing local functions in src folder\n",
        "sys.path.append('../src/')\n",
        "from functions import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_juJ_OFWIC7"
      },
      "source": [
        "## Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1YYF0kFKWIC8",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#loading dataset from Gdrive\n",
        "# fname_2007etp = \"https://drive.google.com/file/d/16JXrTBSgEJH4_30zlFFBye1GRHh5h4O0/view?usp=share_link\"\n",
        "# fname_2007etp = 'https://drive.google.com/uc?id=' + fname_2007etp.split('/')[-2]\n",
        "\n",
        "# #updated dataset\n",
        "# #fname_2015 = \"https://drive.google.com/file/d/1Fb7LFd97aJm0ySb0A48_znfe9KQzaUZO/view?usp=share_link\"\n",
        "# #fname_2015 = 'https://drive.google.com/uc?id=' + fname_2015.split('/')[-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "drLTSJB_c6tO",
        "outputId": "90abcbde-2220-4bda-dbc0-c28d58a9f822"
      },
      "outputs": [],
      "source": [
        "# # downloading gdrive files\n",
        "# url = fname_2007etp\n",
        "# output = \"loan_data_2007_2014.csv\"\n",
        "# gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X0Z0-IhYN0P",
        "outputId": "f58cf2aa-c301-45ca-a1ac-992602d78569"
      },
      "outputs": [],
      "source": [
        "loan_data= pd.read_csv(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pvBxw-TWIC9"
      },
      "source": [
        "## Exploring Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BIRJGSOWIC-",
        "outputId": "36fb62c8-08cb-4f90-d028-d5fb3009ec29"
      },
      "outputs": [],
      "source": [
        "# Uncomment below to set the pandas dataframe options to display all columns/ rows.\n",
        "#pd.options.display.max_columns = None\n",
        "#pd.options.display.max_rows = None\n",
        "\n",
        "loan_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "0axbkggZdY4T",
        "outputId": "99a48982-747b-465d-95f2-1efa4fa75e44"
      },
      "outputs": [],
      "source": [
        "loan_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "rbJn9umLdYqk",
        "outputId": "aa713a53-7838-45c5-e46e-04eeeb1cf913"
      },
      "outputs": [],
      "source": [
        "loan_data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJOOxqiDdnNY",
        "outputId": "ea34f0e9-b6e6-4c29-db4b-efec5ec3b566"
      },
      "outputs": [],
      "source": [
        "loan_data.columns.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Tayb6YBWIDD",
        "outputId": "8ddfa0c0-7b1c-4d33-fa96-9276adae4ed4"
      },
      "outputs": [],
      "source": [
        "# Displaying column names with non missing cases and datatype\n",
        "loan_data.info()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z0_m4PjN4o9G"
      },
      "source": [
        "There are 74 columns in our dataset. There are several empty cells. It is neccessary to concentrate on some of the columns and handle the empty cells in the coming sections.\n",
        "\n",
        "After some trial and errors, we come up with the following columns that are found significant to be kept for the predictive models. Therefore, preprocessing will be applied solely on the following columns: \n",
        "\n",
        "Attn: The preprocessing part is lengthy and takes some time to overview. However, it is repetitive and not complex.\n",
        "\n",
        "---\n",
        "**Discrete Variables**\n",
        "\n",
        "1. 'grade': assigned loan grade  \n",
        "2. 'sub_grade': LC assigned loan subgrade taxliens\n",
        "3. 'home_ownership': the home ownership status provided by the borrower during registration. Values are: RENT, OWN, MORTGAGE, OTHER.\n",
        "4. addr_state: The state provided by the borrower in the loan application\n",
        "5. 'verification_status': Indicates if the borrowers' joint income was verified by LC, not verified, or if the income source was verified\n",
        "6. 'purpose': A category provided by the borrower for the loan request.\n",
        "7. 'initial_list_status': The initial listing status of the loan. Possible values are ‚Äì W, F\n",
        "\n",
        "---\n",
        "**Continuous Variables**\n",
        "1. 'term': number of payments on the loan. Values are in months and can be either 36 or 60.\n",
        "2. 'emp_length': Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.\n",
        "3. 'int_rate': Interest rate on the loan\n",
        "4. 'mths_since_earliest_cr_line': date the borrower's earliest reported credit line was opened\n",
        "5. 'delinq_2yrs': The number of 30+ days past-due incidences of delinquency in the borrower's credit file for the past 2 years\n",
        "6. 'inq_last_6mths': The number of inquiries in past 6 months (excluding auto and mortgage inquiries)\n",
        "7. 'open_acc': The number of open credit lines in the borrower's credit file\n",
        "8. 'pub_rec' : Number of derogatory public records\n",
        "9. 'total_acc': The total number of credit lines currently in the borrower's credit file\n",
        "10. 'acc_now_delinq': The number of accounts on which the borrower is now delinquent.\n",
        "11. 'total_rev_hi_lim': Total revolving high credit/credit limit\n",
        "12. 'annual_inc': The self-reported annual income provided by the borrower during registration.\n",
        "13. 'dti': A ratio calculated using the borrower‚Äôs total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower‚Äôs self-reported monthly income.\n",
        "14. 'mths_since_last_delinq': The number of months since the borrower's last delinquency.\n",
        "15. 'mths_since_last_record': The number of months since the last public record.\n",
        "\n",
        "\n",
        "\n",
        "Please note that the following column is not considered in the example herein but would have improved the prediction scores.\n",
        "* 'mths_since_issue_d': Months since most recent issue d \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIU1UmwAd_JW"
      },
      "source": [
        "# 2 General Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r5Dwl0ajZRm"
      },
      "source": [
        "## a Discrete variables - Dummy columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "77IDwSLvjFvM",
        "outputId": "629d3c78-c8d6-4383-ce06-8396f5eb3fda"
      },
      "outputs": [],
      "source": [
        "#creating dummy variables. adding new columns of values 1 or 0. \n",
        "# ex for Gender=Male, we use 0 Non 1 True. etc\n",
        "# single dummy variable is sufficient for two categories\n",
        "# if there are 4 categories, we need only 3 categories in our prediction model\n",
        "# we use the function \n",
        "pd.get_dummies(loan_data['grade'], prefix = 'grade', prefix_sep = ':').head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2XPby630Ew6M"
      },
      "outputs": [],
      "source": [
        "dummy_columns = ['grade','sub_grade','home_ownership','verification_status',\n",
        "                 'loan_status','purpose','addr_state','initial_list_status']\n",
        "\n",
        "df_Dummies = pd.DataFrame()\n",
        "for col in dummy_columns:\n",
        "  df_Dummy= pd.get_dummies(loan_data[col], prefix = col, prefix_sep = ':')\n",
        "  df_Dummies = pd.concat([df_Dummies,df_Dummy ], axis=1)\n",
        "  #print(loan_data_Dummies.head())\n",
        "  # = pd.concat([loan_data,loan_data_Dummies],axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD0dNQMZEip3",
        "outputId": "bbb30a71-06bc-42ab-c790-f4150daf8cf5"
      },
      "outputs": [],
      "source": [
        "#list of all dummy columns. \n",
        "df_Dummies.columns.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "u6hMHDX0GylG"
      },
      "outputs": [],
      "source": [
        "#merging dummy columns with the main dataset\n",
        "loan_data = pd.concat([loan_data,df_Dummies],axis = 1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vmTuSOB6eCtq"
      },
      "source": [
        "## b Continuous variables - Dt format conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZDJrl6NeB4q",
        "outputId": "e53dc7d8-c40a-4920-c288-9ee26f1e6f8b"
      },
      "outputs": [],
      "source": [
        "#lets convert emp_length into integer\n",
        "loan_data['emp_length'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R_ngIADd6X4",
        "outputId": "5b92b798-4c33-4224-8686-775d372f08d8"
      },
      "outputs": [],
      "source": [
        "# Clean and convert 'emp_length' to numeric\n",
        "loan_data['emp_length_int'] = (\n",
        "    loan_data['emp_length']\n",
        "    .str.replace(r'\\+ years?|< 1 year|n/a', '0', regex=True)  # Handle '+ years', '< 1 year', and 'n/a'\n",
        "    .str.replace(r' years?| year', '', regex=True)            # Remove 'year' or 'years'\n",
        ")\n",
        "\n",
        "# Convert to numeric type\n",
        "loan_data['emp_length_int'] = pd.to_numeric(loan_data['emp_length_int'], errors='coerce')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cyfMvSmldu-P"
      },
      "outputs": [],
      "source": [
        "loan_data['emp_length_int']=pd.to_numeric(loan_data['emp_length_int'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWl3jvPBfUyF",
        "outputId": "74940e47-f822-4078-f441-78ed9b317668"
      },
      "outputs": [],
      "source": [
        "# date variables not in dt format\n",
        "loan_data['earliest_cr_line']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qq2dhSy6fewH"
      },
      "outputs": [],
      "source": [
        "#converting date column to format %b-%y : Apr-03 => 2003-04-03\n",
        "loan_data['earliest_cr_line_date']=pd.to_datetime(loan_data['earliest_cr_line'],format = '%b-%y')\n",
        "#calculating the months since a default date taken as 2017-12-01\n",
        "diff_cr_line = pd.to_datetime('2017-12-01') - loan_data['earliest_cr_line_date']\n",
        "loan_data['mths_since_earliest_cr_line'] = round(pd.to_numeric( diff_cr_line / np.timedelta64(1, 'M')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6y6w1CeghvU",
        "outputId": "61c7cf7a-8b39-4369-ea5e-2470723e29ec"
      },
      "outputs": [],
      "source": [
        "loan_data['mths_since_earliest_cr_line'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C0lASkEqgtXK",
        "outputId": "f28eda8c-8575-405b-87bb-81f65462c9fd"
      },
      "outputs": [],
      "source": [
        "#finding out why there are negative values in our dataset\n",
        "m1 = loan_data['mths_since_earliest_cr_line']<0\n",
        "loan_data.loc[m1,['earliest_cr_line','earliest_cr_line_date','mths_since_earliest_cr_line']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "azpC1pJphcYv"
      },
      "outputs": [],
      "source": [
        "# it is neccessary to handle negative values. they are due to the 196x data read as 206x\n",
        "# we take the maximum month difference to replace negative values\n",
        "loan_data.loc[m1,'mths_since_earliest_cr_line'] = loan_data.loc[:,'mths_since_earliest_cr_line'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGP34ipHiPQo",
        "outputId": "e05d3d47-19b7-44d4-d6bf-18d55eeb58fd"
      },
      "outputs": [],
      "source": [
        "#let's convert term column to integer format\n",
        "loan_data['term']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPwLXHgHipyA",
        "outputId": "874b3270-ca1a-4760-b455-d38f6ff1190d"
      },
      "outputs": [],
      "source": [
        "loan_data['term_int'] = loan_data['term'].str.replace(' months', '').astype(int)\n",
        "loan_data['term_int'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PsqObNxixrC",
        "outputId": "7fb43aa8-51f7-4ee8-d125-7e57af580823"
      },
      "outputs": [],
      "source": [
        "# Assuming we are in December 2017\n",
        "loan_data['issue_d_date'] = pd.to_datetime(loan_data['issue_d'], format = '%b-%y')\n",
        "\n",
        "#calculating the month difference from 2017-12-01\n",
        "# We calculate the difference between two dates in months, turn it to numeric datatype and round it.\n",
        "diff_issue_d = pd.to_datetime('2017-12-01') - loan_data['issue_d_date']\n",
        "loan_data['mths_since_issue_d'] = round(pd.to_numeric( diff_issue_d / np.timedelta64(1, 'M')))\n",
        "\n",
        "# Showing some descriptive statisics for the values of a column.\n",
        "loan_data['mths_since_issue_d'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrQuEX5flqhP"
      },
      "source": [
        "## c Checking for missing values or cleaning them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqZbGTsOlebX",
        "outputId": "0187385e-e8ef-4771-dbcc-348b4d181586"
      },
      "outputs": [],
      "source": [
        "pd.options.display.max_rows = None\n",
        "loan_data.isnull().sum().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "W97HRo-hluef"
      },
      "outputs": [],
      "source": [
        "pd.options.display.max_rows = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "HTiXq57mmJJN"
      },
      "outputs": [],
      "source": [
        "# filling up the empty rows that will be used in our model.\n",
        "# we use funded_amnt for the missing total_rev_hi_lim values\n",
        "# fundedAmnt The total amount committed to that loan at that point in time.\n",
        "loan_data['total_rev_hi_lim'].fillna(loan_data['funded_amnt'],inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "p_osPqX8mS4E"
      },
      "outputs": [],
      "source": [
        "# for the missing values in annual_inc, mean value is considered.  \n",
        "loan_data['annual_inc'].fillna(loan_data['annual_inc'].mean(),inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "bQCTwSBKmjv6"
      },
      "outputs": [],
      "source": [
        "# for the missing values below, we consider 0\n",
        "loan_data['mths_since_earliest_cr_line'].fillna(0,inplace = True)\n",
        "loan_data['acc_now_delinq'].fillna(0, inplace=True)\n",
        "loan_data['total_acc'].fillna(0, inplace=True)\n",
        "loan_data['pub_rec'].fillna(0, inplace=True)\n",
        "loan_data['open_acc'].fillna(0, inplace=True)\n",
        "loan_data['inq_last_6mths'].fillna(0, inplace=True)\n",
        "loan_data['delinq_2yrs'].fillna(0, inplace=True)\n",
        "loan_data['emp_length_int'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGDk3Wg-nSaX"
      },
      "source": [
        "# 3 PD Model Definition\n",
        "\n",
        "Remember: EL = PD * LGB * EDA\n",
        "\n",
        "First, we need to define the default definition. Good and bad definitions are needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie5ye5mxpfkx"
      },
      "source": [
        "## a Data Preparation - Dependent Variable\n",
        "\n",
        "Dependent variable. Good/Bad - Defaulted borrower Definition. Default and Non-default Accounts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mvHFpuGms5W",
        "outputId": "6c02d4ea-a831-4c29-b408-0a0f5ae0fbc3"
      },
      "outputs": [],
      "source": [
        "# let's explore loan_status column further and findout the proportion of data\n",
        "loan_data['loan_status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHv6SmP6pvNs",
        "outputId": "48b484e9-9a3f-4373-ab98-a31a5e1fcd31"
      },
      "outputs": [],
      "source": [
        "loan_data['loan_status'].value_counts() / loan_data['loan_status'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "GbwCx2Lup8yV"
      },
      "outputs": [],
      "source": [
        "# if the result == 'Charged Off', 'Default', 'Does not meet the credit policy. Status: Charged Off.',\n",
        "#                   'Late (31-120 days)', We take 0 (Bad). Otherwise = 1 (Good)\n",
        "bad_def = ['Charged Off', 'Default','Does not meet the credit policy. Status: Charged Off.',\n",
        "           'Late (31-120 days)']\n",
        "\n",
        "#good is 1, bad is 0\n",
        "loan_data['good_bad'] = np.where(loan_data['loan_status'].isin(bad_def), 0, 1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqpvVmg4qqEH",
        "outputId": "8f725b20-bed6-4a15-a67c-39201c6b8ec3"
      },
      "outputs": [],
      "source": [
        "loan_data['good_bad'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hvdQGnNq_CI",
        "outputId": "0fe49d8a-8853-4abe-8983-98e53c7b6946"
      },
      "outputs": [],
      "source": [
        "loan_data['good_bad'].value_counts() / loan_data['good_bad'].count() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkbhEOkKQanS"
      },
      "source": [
        "##**b Train n Test Set Split**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rSWfObWv7tld"
      },
      "outputs": [],
      "source": [
        "#splitting data into test and split datasets. 80:20 train to test ratio\n",
        "inputs_train, inputs_test, targets_train, targets_test = train_test_split(\n",
        "    loan_data.drop('good_bad',axis = 1), loan_data['good_bad'], test_size=0.2, \n",
        "    random_state= 75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1Kja27F8_Ey",
        "outputId": "6cd8cfc5-8e74-4cac-8813-b865f041f9cc"
      },
      "outputs": [],
      "source": [
        "inputs_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd68JUps94Iy",
        "outputId": "b51a030c-647a-4ebd-d743-a8c82f13a3d2"
      },
      "outputs": [],
      "source": [
        "inputs_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8fJI1Bm-JQT"
      },
      "source": [
        "##**c Selecting test or train set for preproc.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "IjY2sU0c97VN"
      },
      "outputs": [],
      "source": [
        "#first run it for train set and then for test set for the preprocessing\n",
        "df_inputs_prepr = inputs_train\n",
        "df_targets_prepr = targets_train\n",
        "#test set\n",
        "#df_inputs_prepr = inputs_test\n",
        "#df_targets_prepr = targets_test\n",
        "\n",
        "#next we will calculate Weight of Evidence (WoE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z5kVKR5cJzN"
      },
      "source": [
        "#4 Discrete Data Preparation - WoE"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BsLf4ljgUE2e"
      },
      "source": [
        "**Let's automate the calculation of WoE and IV**\n",
        "\n",
        "**Weight of Evidence- Woe**\n",
        "To what extent an independent variable would predict a dependent variable\n",
        "\n",
        "Positive WOE means Distribution of Goods > Distribution of Bads  \n",
        "Negative WOE means Distribution of Goods < Distribution of Bads  \n",
        "Hint : Log of a number > 1 means positive value. If less than 1, it means negative value.  \n",
        "\n",
        "Two ways to classify groups in WoE calculations  \n",
        "\n",
        "1. Fine Classing: Create 10 to 20 bins/groups for a continuous independent variable and then calculate WOE and IV of the variable. \n",
        "2. Coarse Classing: Combine adjacent categories with similar WOE scores\n",
        "\n",
        "---\n",
        "**Information Value (IV)**\n",
        "\n",
        "Information value is a useful technique to select important variables in a predictive model. It represents how much independent information it brings originally to explain dependent value. It helps to rank variables on the basis of their importance. The IV is calculated using the following formula :  \n",
        "\n",
        "IV = ‚àë (% of non-events - % of events) * WOE\n",
        "\n",
        "IV categories  \n",
        "* Less than 0.02 => \tNot useful for prediction   \n",
        "* 0.02 to 0.1\t=> Weak predictive Power  \n",
        "* 0.1 to 0.3\t=> Medium predictive Power  \n",
        "* 0.3 to 0.5 => \tStrong predictive Power  \n",
        "* '>0.5 =>\tSuspicious Predictive Power  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T1eN1KeIauH"
      },
      "source": [
        "## Part 1 Discrete Variables: Dummy Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "u57P-HioE39X",
        "outputId": "08df092c-cd72-4718-8073-e06117fad7d5"
      },
      "outputs": [],
      "source": [
        "df_temp = woe_discrete(df_inputs_prepr, 'grade',df_targets_prepr)\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1YBCEzQGCDR"
      },
      "source": [
        "  **Drawing the plots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "QA2KB92WIEn1",
        "outputId": "ef25cdae-77a8-4b7c-9654-588041c93cff"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHNyVcK_If7g"
      },
      "source": [
        "As we can see, WoE increases with increasing external credit grade. \n",
        "That means loans with greater external grade are better in general."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "uKd9fO-DIGca",
        "outputId": "511d37fe-6d43-466a-b06e-142d2fa03a1c"
      },
      "outputs": [],
      "source": [
        "df_temp = woe_discrete(df_inputs_prepr, 'home_ownership',df_targets_prepr)\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "BEVghpbFJtqK",
        "outputId": "f0f629de-792c-42a1-fc11-f1d2bc2db15c"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2axco7TJ8WK"
      },
      "source": [
        "We don't want dummy variables for None, Other and Any.\n",
        "They are undenrepresented categories. \n",
        "\n",
        "Let's combine None, Other and Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "7BJWN8qbJ71l"
      },
      "outputs": [],
      "source": [
        "df_inputs_prepr['home_ownership:RENT_OTHER_NONE_ANY'] = sum ([df_inputs_prepr['home_ownership:RENT'], df_inputs_prepr['home_ownership:OTHER'],\n",
        "                                                              df_inputs_prepr['home_ownership:NONE'], df_inputs_prepr['home_ownership:ANY'],])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVj14YZxL0SI",
        "outputId": "dd0e488e-172a-43d1-c147-acb8b2e8adcc"
      },
      "outputs": [],
      "source": [
        "df_inputs_prepr['addr_state'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "10pyMXfzLz8J",
        "outputId": "2fa2f037-6f94-48ef-8460-1ce98221a0ec"
      },
      "outputs": [],
      "source": [
        "df_temp = woe_discrete(df_inputs_prepr,'addr_state', df_targets_prepr)\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "q9hCBQECMKc0",
        "outputId": "2af0beb4-76a4-4c8e-9760-95c0a06a0e02"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_-waHD9M4Id"
      },
      "source": [
        "Very few observations for first two and last two states + North Dakato no data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "oimGpjLbMKIF"
      },
      "outputs": [],
      "source": [
        "if ['addr_state:ND'] in df_inputs_prepr.columns.values:\n",
        "  pass\n",
        "else:\n",
        "  df_inputs_prepr['addr_state:ND'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "9dkBGfj8MKA7",
        "outputId": "02c2181a-0702-48eb-d996-dacf2355ed94"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp.iloc[2:-2,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOhHCH13NQr7"
      },
      "source": [
        "Lets combine Nevada with Florida. NE, IA, NV => FL\n",
        "\n",
        "If no data, go with the worst case scenario. \n",
        "\n",
        "Last 4 cols can be regrouped together. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "Mt7pn6gVMJ55",
        "outputId": "fe4015b7-8d56-497a-f575-2bf6e062a365"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp.iloc[6:-6,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBUm9fH3NypF"
      },
      "source": [
        "rest of the states can be in the same group. We can seperate NY and CA.\n",
        "\n",
        "check with the borrowers, try to regroup some states together. \n",
        "\n",
        "TX also has high number of borrowers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "XSoVw6F-MJw3"
      },
      "outputs": [],
      "source": [
        "# We create the following categories:\n",
        "# 'ND' 'NE' 'IA' NV' 'FL' 'HI' 'AL'\n",
        "# 'NM' 'VA'\n",
        "# 'NY'\n",
        "# 'OK' 'TN' 'MO' 'LA' 'MD' 'NC'\n",
        "# 'CA'\n",
        "# 'UT' 'KY' 'AZ' 'NJ'\n",
        "# 'AR' 'MI' 'PA' 'OH' 'MN'\n",
        "# 'RI' 'MA' 'DE' 'SD' 'IN'\n",
        "# 'GA' 'WA' 'OR'\n",
        "# 'WI' 'MT'\n",
        "# 'TX'\n",
        "# 'IL' 'CT'\n",
        "# 'KS' 'SC' 'CO' 'VT' 'AK' 'MS'\n",
        "# 'WV' 'NH' 'WY' 'DC' 'ME' 'ID'\n",
        "\n",
        "# 'IA_NV_HI_ID_AL_FL' will be the reference category.\n",
        "\n",
        "df_inputs_prepr['addr_state:ND_NE_IA_NV_FL_HI_AL'] = sum([df_inputs_prepr['addr_state:ND'], df_inputs_prepr['addr_state:NE'],\n",
        "                                              df_inputs_prepr['addr_state:IA'], df_inputs_prepr['addr_state:NV'],\n",
        "                                              df_inputs_prepr['addr_state:FL'], df_inputs_prepr['addr_state:HI'],\n",
        "                                                          df_inputs_prepr['addr_state:AL']])\n",
        "\n",
        "df_inputs_prepr['addr_state:NM_VA'] = sum([df_inputs_prepr['addr_state:NM'], df_inputs_prepr['addr_state:VA']])\n",
        "\n",
        "df_inputs_prepr['addr_state:OK_TN_MO_LA_MD_NC'] = sum([df_inputs_prepr['addr_state:OK'], df_inputs_prepr['addr_state:TN'],\n",
        "                                              df_inputs_prepr['addr_state:MO'], df_inputs_prepr['addr_state:LA'],\n",
        "                                              df_inputs_prepr['addr_state:MD'], df_inputs_prepr['addr_state:NC']])\n",
        "\n",
        "df_inputs_prepr['addr_state:UT_KY_AZ_NJ'] = sum([df_inputs_prepr['addr_state:UT'], df_inputs_prepr['addr_state:KY'],\n",
        "                                              df_inputs_prepr['addr_state:AZ'], df_inputs_prepr['addr_state:NJ']])\n",
        "\n",
        "df_inputs_prepr['addr_state:AR_MI_PA_OH_MN'] = sum([df_inputs_prepr['addr_state:AR'], df_inputs_prepr['addr_state:MI'],\n",
        "                                              df_inputs_prepr['addr_state:PA'], df_inputs_prepr['addr_state:OH'],\n",
        "                                              df_inputs_prepr['addr_state:MN']])\n",
        "\n",
        "df_inputs_prepr['addr_state:RI_MA_DE_SD_IN'] = sum([df_inputs_prepr['addr_state:RI'], df_inputs_prepr['addr_state:MA'],\n",
        "                                              df_inputs_prepr['addr_state:DE'], df_inputs_prepr['addr_state:SD'],\n",
        "                                              df_inputs_prepr['addr_state:IN']])\n",
        "\n",
        "df_inputs_prepr['addr_state:GA_WA_OR'] = sum([df_inputs_prepr['addr_state:GA'], df_inputs_prepr['addr_state:WA'],\n",
        "                                              df_inputs_prepr['addr_state:OR']])\n",
        "\n",
        "df_inputs_prepr['addr_state:WI_MT'] = sum([df_inputs_prepr['addr_state:WI'], df_inputs_prepr['addr_state:MT']])\n",
        "\n",
        "df_inputs_prepr['addr_state:IL_CT'] = sum([df_inputs_prepr['addr_state:IL'], df_inputs_prepr['addr_state:CT']])\n",
        "\n",
        "df_inputs_prepr['addr_state:KS_SC_CO_VT_AK_MS'] = sum([df_inputs_prepr['addr_state:KS'], df_inputs_prepr['addr_state:SC'],\n",
        "                                              df_inputs_prepr['addr_state:CO'], df_inputs_prepr['addr_state:VT'],\n",
        "                                              df_inputs_prepr['addr_state:AK'], df_inputs_prepr['addr_state:MS']])\n",
        "\n",
        "df_inputs_prepr['addr_state:WV_NH_WY_DC_ME_ID'] = sum([df_inputs_prepr['addr_state:WV'], df_inputs_prepr['addr_state:NH'],\n",
        "                                              df_inputs_prepr['addr_state:WY'], df_inputs_prepr['addr_state:DC'],\n",
        "                                              df_inputs_prepr['addr_state:ME'], df_inputs_prepr['addr_state:ID']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5EcTb2xLt5V"
      },
      "source": [
        "## Part 2 Discrete Variables: Dummy Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jadvGsFcIVr0"
      },
      "source": [
        "**Let's repeat the same preprocessing on verification_status**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "M_tJlueuImb3",
        "outputId": "b9a9c9e6-38f9-4c20-896a-115608fda9bf"
      },
      "outputs": [],
      "source": [
        "# 'verification_status'\n",
        "df_temp = woe_discrete(df_inputs_prepr, 'verification_status', df_targets_prepr)\n",
        "# We calculate weight of evidence.\n",
        "df_temp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "Fj1VgPdtIpic",
        "outputId": "607d9ecd-c69f-4787-c65f-c42e6f28330b"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9FM_MA2Ick2"
      },
      "source": [
        "OK\n",
        "**How about purpose row?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "JIgeBErgI499",
        "outputId": "f975a42d-2e6e-4a01-fcfa-49f73a7b9ed5"
      },
      "outputs": [],
      "source": [
        "# 'purpose'\n",
        "df_temp = woe_discrete(df_inputs_prepr, 'purpose', df_targets_prepr)\n",
        "# We calculate weight of evidence.\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "M5pb-1N6I45O",
        "outputId": "b0e62f2f-6a58-4215-ee0d-59618ba835c8"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp, 90)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "FIPHkhwhI40x"
      },
      "outputs": [],
      "source": [
        "# We combine 'educational', 'small_business', 'wedding', 'renewable_energy', 'moving', 'house' in one category: 'educ__sm_b__wedd__ren_en__mov__house'.\n",
        "# We combine 'other', 'medical', 'vacation' in one category: 'oth__med__vacation'.\n",
        "# We combine 'major_purchase', 'car', 'home_improvement' in one category: 'major_purch__car__home_impr'.\n",
        "# We leave 'debt_consolidtion' in a separate category.\n",
        "# We leave 'credit_card' in a separate category.\n",
        "# 'educ__sm_b__wedd__ren_en__mov__house' will be the reference category.\n",
        "df_inputs_prepr['purpose:educ__sm_b__wedd__ren_en__mov__house'] = sum([df_inputs_prepr['purpose:educational'], df_inputs_prepr['purpose:small_business'],\n",
        "                                                                 df_inputs_prepr['purpose:wedding'], df_inputs_prepr['purpose:renewable_energy'],\n",
        "                                                                 df_inputs_prepr['purpose:moving'], df_inputs_prepr['purpose:house']])\n",
        "df_inputs_prepr['purpose:oth__med__vacation'] = sum([df_inputs_prepr['purpose:other'], df_inputs_prepr['purpose:medical'],\n",
        "                                             df_inputs_prepr['purpose:vacation']])\n",
        "df_inputs_prepr['purpose:major_purch__car__home_impr'] = sum([df_inputs_prepr['purpose:major_purchase'], df_inputs_prepr['purpose:car'],\n",
        "                                                        df_inputs_prepr['purpose:home_improvement']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOgfT6cmJg4f"
      },
      "source": [
        "**initial list status***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Lre3P2IhI4xF",
        "outputId": "db62573a-a0b7-4463-bd5d-0aa59cfa6809"
      },
      "outputs": [],
      "source": [
        "# 'initial_list_status'\n",
        "df_temp = woe_discrete(df_inputs_prepr, 'initial_list_status', df_targets_prepr)\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "sXFmkNHYI4ts",
        "outputId": "15960a55-b308-4396-f76b-ae47c6aa68a0"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0C813ymLibo"
      },
      "source": [
        "#5 Continous Data Preparation - WoE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOZzQCcCMCY9",
        "outputId": "c0a8e6e4-02f6-45e3-822e-c0a38d582874"
      },
      "outputs": [],
      "source": [
        "df_inputs_prepr['term_int'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "cJRPWKYuMR9c",
        "outputId": "d76896f3-9f5c-4caa-886f-13a78253c6c7"
      },
      "outputs": [],
      "source": [
        "df_temp = woe_ordered_continuous ( df_inputs_prepr, 'term_int', df_targets_prepr)\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "c7m-NbVEMe0E",
        "outputId": "bf92c006-5dd0-450d-8497-219e8abffefb"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "NPxohqJoMkFh"
      },
      "outputs": [],
      "source": [
        "df_inputs_prepr['term:36'] = np.where((df_inputs_prepr['term_int']==36),1,0)\n",
        "df_inputs_prepr['term:60'] = np.where((df_inputs_prepr['term_int']==60),1,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU6qi8dNM9KG",
        "outputId": "57082d1b-4f1f-4a99-bc7c-59fe18e49871"
      },
      "outputs": [],
      "source": [
        "df_inputs_prepr['emp_length_int'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "Ii4EzhDFNLss",
        "outputId": "d14b8340-ea98-4c35-def0-a4cc96b523e9"
      },
      "outputs": [],
      "source": [
        "df_temp = woe_ordered_continuous (df_inputs_prepr,'emp_length_int',df_targets_prepr)\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "VQVqQbxCNYPn",
        "outputId": "b10a8bad-da15-4144-a3b1-63d4eeae7246"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "SPEWrrthNg65"
      },
      "outputs": [],
      "source": [
        "# We create the following categories: '0', '1', '2 - 4', '5 - 6', '7 - 9', '10'\n",
        "# '0' will be the reference category\n",
        "df_inputs_prepr['emp_length:0'] = np.where(df_inputs_prepr['emp_length_int'].isin([0]), 1, 0)\n",
        "df_inputs_prepr['emp_length:1'] = np.where(df_inputs_prepr['emp_length_int'].isin([1]), 1, 0)\n",
        "df_inputs_prepr['emp_length:2-4'] = np.where(df_inputs_prepr['emp_length_int'].isin(range(2, 5)), 1, 0)\n",
        "df_inputs_prepr['emp_length:5-6'] = np.where(df_inputs_prepr['emp_length_int'].isin(range(5, 7)), 1, 0)\n",
        "df_inputs_prepr['emp_length:7-9'] = np.where(df_inputs_prepr['emp_length_int'].isin(range(7, 10)), 1, 0)\n",
        "df_inputs_prepr['emp_length:10'] = np.where(df_inputs_prepr['emp_length_int'].isin([10]), 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6jb-_t7Pbgd"
      },
      "source": [
        "##Part 1 Continous Variables - Dummy Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yso0cr1IOOgw",
        "outputId": "81697b06-50f2-4a8c-db58-c739a83a2947"
      },
      "outputs": [],
      "source": [
        "df_inputs_prepr['mths_since_issue_d'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "CwtQZSVQPloG"
      },
      "outputs": [],
      "source": [
        "#let's do fine classing first: to roughly group the values into categories\n",
        "#second, we need to do coarse classing: determining final categories, combining few of initial fine classing\n",
        "# categories into bigger categories, if needed\n",
        "df_inputs_prepr['mths_since_issue_d_factor'] = pd.cut(df_inputs_prepr['mths_since_issue_d'],50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0b9_c34Pzrm",
        "outputId": "6e717317-63e7-4a6e-c40f-5b7329c40722"
      },
      "outputs": [],
      "source": [
        "df_inputs_prepr['mths_since_issue_d_factor'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "ZqGeWu4sP5IE",
        "outputId": "b09e611f-ca09-4ad1-a0d6-bed0c5cac86d"
      },
      "outputs": [],
      "source": [
        "df_temp = woe_ordered_continuous (df_inputs_prepr, 'mths_since_issue_d_factor',df_targets_prepr)\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "8x7TnbxAQilP",
        "outputId": "166e1ac9-4f9e-4ea9-ce03-2f28961fb868"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp,90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "NsDCS2IcQopo"
      },
      "outputs": [],
      "source": [
        "# '< 9.548', '9.548 - 12.025', '12.025 - 15.74', '15.74 - 20.281', '> 20.281'\n",
        "df_inputs_prepr['int_rate:<9.548'] = np.where((df_inputs_prepr['int_rate'] <= 9.548), 1, 0)\n",
        "df_inputs_prepr['int_rate:9.548-12.025'] = np.where((df_inputs_prepr['int_rate'] > 9.548) & (df_inputs_prepr['int_rate'] <= 12.025), 1, 0)\n",
        "df_inputs_prepr['int_rate:12.025-15.74'] = np.where((df_inputs_prepr['int_rate'] > 12.025) & (df_inputs_prepr['int_rate'] <= 15.74), 1, 0)\n",
        "df_inputs_prepr['int_rate:15.74-20.281'] = np.where((df_inputs_prepr['int_rate'] > 15.74) & (df_inputs_prepr['int_rate'] <= 20.281), 1, 0)\n",
        "df_inputs_prepr['int_rate:>20.281'] = np.where((df_inputs_prepr['int_rate'] > 20.281), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zFgHsYP7Sz4X",
        "outputId": "6d812bad-a0e1-4542-b76d-9594a7da66cd"
      },
      "outputs": [],
      "source": [
        "# funded_amnt\n",
        "df_inputs_prepr['funded_amnt_factor'] = pd.cut(df_inputs_prepr['funded_amnt'], 50)\n",
        "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
        "df_temp = woe_ordered_continuous(df_inputs_prepr, 'funded_amnt_factor', df_targets_prepr)\n",
        "# We calculate weight of evidence.\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "VsTftIvdS2_A",
        "outputId": "99e6a616-d685-4308-af8e-4eaab7524059"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp, 90)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_Jd-KjZsS3lm",
        "outputId": "0eb79279-16ed-4fb4-b8bd-b7998527c25d"
      },
      "outputs": [],
      "source": [
        "# mths_since_earliest_cr_line\n",
        "df_inputs_prepr['mths_since_earliest_cr_line_factor'] = pd.cut(df_inputs_prepr['mths_since_earliest_cr_line'], 50)\n",
        "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
        "df_temp = woe_ordered_continuous(df_inputs_prepr, 'mths_since_earliest_cr_line_factor', df_targets_prepr)\n",
        "# We calculate weight of evidence.\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "TwbY3cckTFg1",
        "outputId": "48bce121-cae0-4cea-9ccd-2e09d82f9fdd"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp, 90)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "NK6nQD0YTIXH"
      },
      "outputs": [],
      "source": [
        "# We create the following categories:\n",
        "# < 140, # 141 - 164, # 165 - 247, # 248 - 270, # 271 - 352, # > 352\n",
        "df_inputs_prepr['mths_since_earliest_cr_line:<140'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(140)), 1, 0)\n",
        "df_inputs_prepr['mths_since_earliest_cr_line:141-164'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(140, 165)), 1, 0)\n",
        "df_inputs_prepr['mths_since_earliest_cr_line:165-247'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(165, 248)), 1, 0)\n",
        "df_inputs_prepr['mths_since_earliest_cr_line:248-270'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(248, 271)), 1, 0)\n",
        "df_inputs_prepr['mths_since_earliest_cr_line:271-352'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(271, 353)), 1, 0)\n",
        "df_inputs_prepr['mths_since_earliest_cr_line:>352'] = np.where(df_inputs_prepr['mths_since_earliest_cr_line'].isin(range(353, int(df_inputs_prepr['mths_since_earliest_cr_line'].max()))), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "-tbeiHZITg0t",
        "outputId": "08713dde-e941-4462-bdb3-ae55088a39d2"
      },
      "outputs": [],
      "source": [
        "# delinq_2yrs\n",
        "df_temp = woe_ordered_continuous(df_inputs_prepr, 'delinq_2yrs', df_targets_prepr)\n",
        "# We calculate weight of evidence.\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "zWy57IjpTi_V",
        "outputId": "98d5f86f-42b2-440c-bd24-c8de6a5ae8a6"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "kWew_SHfTnZa"
      },
      "outputs": [],
      "source": [
        "# Categories: 0, 1-3, >=4\n",
        "df_inputs_prepr['delinq_2yrs:0'] = np.where((df_inputs_prepr['delinq_2yrs'] == 0), 1, 0)\n",
        "df_inputs_prepr['delinq_2yrs:1-3'] = np.where((df_inputs_prepr['delinq_2yrs'] >= 1) & (df_inputs_prepr['delinq_2yrs'] <= 3), 1, 0)\n",
        "df_inputs_prepr['delinq_2yrs:>=4'] = np.where((df_inputs_prepr['delinq_2yrs'] >= 9), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "id": "9QKUfI10TrGF",
        "outputId": "38bc5f4d-b8f0-4438-95ad-e61ad639e5be"
      },
      "outputs": [],
      "source": [
        "# inq_last_6mths\n",
        "df_temp = woe_ordered_continuous(df_inputs_prepr, 'inq_last_6mths', df_targets_prepr)\n",
        "# We calculate weight of evidence.\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "hZXF-wzNTyGZ",
        "outputId": "13015d52-9c9e-44b0-e847-6711746bd507"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "4-zgGBCiT04s"
      },
      "outputs": [],
      "source": [
        "# Categories: 0, 1 - 2, 3 - 6, > 6\n",
        "df_inputs_prepr['inq_last_6mths:0'] = np.where((df_inputs_prepr['inq_last_6mths'] == 0), 1, 0)\n",
        "df_inputs_prepr['inq_last_6mths:1-2'] = np.where((df_inputs_prepr['inq_last_6mths'] >= 1) & (df_inputs_prepr['inq_last_6mths'] <= 2), 1, 0)\n",
        "df_inputs_prepr['inq_last_6mths:3-6'] = np.where((df_inputs_prepr['inq_last_6mths'] >= 3) & (df_inputs_prepr['inq_last_6mths'] <= 6), 1, 0)\n",
        "df_inputs_prepr['inq_last_6mths:>6'] = np.where((df_inputs_prepr['inq_last_6mths'] > 6), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fdRcquViT3bZ",
        "outputId": "fd83d51c-aa5a-48bf-ac25-069ab79c10aa"
      },
      "outputs": [],
      "source": [
        "# open_acc\n",
        "df_temp = woe_ordered_continuous(df_inputs_prepr, 'open_acc', df_targets_prepr)\n",
        "# We calculate weight of evidence.\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "3qDkFbMqT42X",
        "outputId": "5f2f9972-e3be-4e87-c71e-f9af88b89077"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp, 90)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "3EbXO2DaT8P9",
        "outputId": "2d5d91bd-9443-490c-a6fb-ed1115f27a5e"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp.iloc[ : 40, :], 90)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "6FTeiDvKUAAX"
      },
      "outputs": [],
      "source": [
        "# Categories: '0', '1-3', '4-12', '13-17', '18-22', '23-25', '26-30', '>30'\n",
        "df_inputs_prepr['open_acc:0'] = np.where((df_inputs_prepr['open_acc'] == 0), 1, 0)\n",
        "df_inputs_prepr['open_acc:1-3'] = np.where((df_inputs_prepr['open_acc'] >= 1) & (df_inputs_prepr['open_acc'] <= 3), 1, 0)\n",
        "df_inputs_prepr['open_acc:4-12'] = np.where((df_inputs_prepr['open_acc'] >= 4) & (df_inputs_prepr['open_acc'] <= 12), 1, 0)\n",
        "df_inputs_prepr['open_acc:13-17'] = np.where((df_inputs_prepr['open_acc'] >= 13) & (df_inputs_prepr['open_acc'] <= 17), 1, 0)\n",
        "df_inputs_prepr['open_acc:18-22'] = np.where((df_inputs_prepr['open_acc'] >= 18) & (df_inputs_prepr['open_acc'] <= 22), 1, 0)\n",
        "df_inputs_prepr['open_acc:23-25'] = np.where((df_inputs_prepr['open_acc'] >= 23) & (df_inputs_prepr['open_acc'] <= 25), 1, 0)\n",
        "df_inputs_prepr['open_acc:26-30'] = np.where((df_inputs_prepr['open_acc'] >= 26) & (df_inputs_prepr['open_acc'] <= 30), 1, 0)\n",
        "df_inputs_prepr['open_acc:>=31'] = np.where((df_inputs_prepr['open_acc'] >= 31), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "hAFQPI1_UEt0",
        "outputId": "f69e2128-e25d-4295-a215-e713dee60332"
      },
      "outputs": [],
      "source": [
        "# pub_rec\n",
        "df_temp = woe_ordered_continuous(df_inputs_prepr, 'pub_rec', df_targets_prepr)\n",
        "# We calculate weight of evidence.\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "jZsGIV6sUHKF",
        "outputId": "9e0d5340-2e24-4b1f-b7fc-9d88160b3a8e"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp, 90)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "dDT8PQ01UIS5"
      },
      "outputs": [],
      "source": [
        "# Categories '0-2', '3-4', '>=5'\n",
        "df_inputs_prepr['pub_rec:0-2'] = np.where((df_inputs_prepr['pub_rec'] >= 0) & (df_inputs_prepr['pub_rec'] <= 2), 1, 0)\n",
        "df_inputs_prepr['pub_rec:3-4'] = np.where((df_inputs_prepr['pub_rec'] >= 3) & (df_inputs_prepr['pub_rec'] <= 4), 1, 0)\n",
        "df_inputs_prepr['pub_rec:>=5'] = np.where((df_inputs_prepr['pub_rec'] >= 5), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5ylExbjsUJ7e",
        "outputId": "fea8491c-e87f-402e-aa25-07ef707c52d6"
      },
      "outputs": [],
      "source": [
        "# total_acc\n",
        "df_inputs_prepr['total_acc_factor'] = pd.cut(df_inputs_prepr['total_acc'], 50)\n",
        "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
        "df_temp = woe_ordered_continuous(df_inputs_prepr, 'total_acc_factor', df_targets_prepr)\n",
        "# We calculate weight of evidence.\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "FQBULOUrUK8Q",
        "outputId": "f7e649e8-60d1-4ffe-bbb7-470e0887bec9"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp, 90)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "TtWfu-KXUNJB"
      },
      "outputs": [],
      "source": [
        "# Categories: '<=27', '28-51', '>51'\n",
        "df_inputs_prepr['total_acc:<=27'] = np.where((df_inputs_prepr['total_acc'] <= 27), 1, 0)\n",
        "df_inputs_prepr['total_acc:28-51'] = np.where((df_inputs_prepr['total_acc'] >= 28) & (df_inputs_prepr['total_acc'] <= 51), 1, 0)\n",
        "df_inputs_prepr['total_acc:>=52'] = np.where((df_inputs_prepr['total_acc'] >= 52), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "1qRd6-efURIm",
        "outputId": "68ff79a5-b8d8-44f1-db73-e714208768f5"
      },
      "outputs": [],
      "source": [
        "# acc_now_delinq\n",
        "df_temp = woe_ordered_continuous(df_inputs_prepr, 'acc_now_delinq', df_targets_prepr)\n",
        "# We calculate weight of evidence.\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "_BVFa5M9UVEg",
        "outputId": "0f7cd988-e13d-495c-9d8d-248b7d1eddeb"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "tdrke5EaUW7e"
      },
      "outputs": [],
      "source": [
        "# Categories: '0', '>=1'\n",
        "df_inputs_prepr['acc_now_delinq:0'] = np.where((df_inputs_prepr['acc_now_delinq'] == 0), 1, 0)\n",
        "df_inputs_prepr['acc_now_delinq:>=1'] = np.where((df_inputs_prepr['acc_now_delinq'] >= 1), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "u09nA3ZqUYyF",
        "outputId": "e91cab02-8908-4e27-f90d-f108fa2b6c12"
      },
      "outputs": [],
      "source": [
        "# total_rev_hi_lim\n",
        "df_inputs_prepr['total_rev_hi_lim_factor'] = pd.cut(df_inputs_prepr['total_rev_hi_lim'], 2000)\n",
        "# Here we do fine-classing: using the 'cut' method, we split the variable into 2000 categories by its values.\n",
        "df_temp = woe_ordered_continuous(df_inputs_prepr, 'total_rev_hi_lim_factor', df_targets_prepr)\n",
        "# We calculate weight of evidence.\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "D7fFHuwaUasS",
        "outputId": "edb99847-5cae-47da-8100-dd4f0cbd3ff2"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp.iloc[: 50, : ], 90)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "YUr4hpYFUczc"
      },
      "outputs": [],
      "source": [
        "# Categories\n",
        "# '<=5K', '5K-10K', '10K-20K', '20K-30K', '30K-40K', '40K-55K', '55K-95K', '>95K'\n",
        "df_inputs_prepr['total_rev_hi_lim:<=5K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] <= 5000), 1, 0)\n",
        "df_inputs_prepr['total_rev_hi_lim:5K-10K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 5000) & (df_inputs_prepr['total_rev_hi_lim'] <= 10000), 1, 0)\n",
        "df_inputs_prepr['total_rev_hi_lim:10K-20K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 10000) & (df_inputs_prepr['total_rev_hi_lim'] <= 20000), 1, 0)\n",
        "df_inputs_prepr['total_rev_hi_lim:20K-30K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 20000) & (df_inputs_prepr['total_rev_hi_lim'] <= 30000), 1, 0)\n",
        "df_inputs_prepr['total_rev_hi_lim:30K-40K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 30000) & (df_inputs_prepr['total_rev_hi_lim'] <= 40000), 1, 0)\n",
        "df_inputs_prepr['total_rev_hi_lim:40K-55K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 40000) & (df_inputs_prepr['total_rev_hi_lim'] <= 55000), 1, 0)\n",
        "df_inputs_prepr['total_rev_hi_lim:55K-95K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 55000) & (df_inputs_prepr['total_rev_hi_lim'] <= 95000), 1, 0)\n",
        "df_inputs_prepr['total_rev_hi_lim:>95K'] = np.where((df_inputs_prepr['total_rev_hi_lim'] > 95000), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EvrO8sFOUfTS",
        "outputId": "ea18ab22-974c-4e9e-aa4d-d97bf23e7ff2"
      },
      "outputs": [],
      "source": [
        "# installment\n",
        "df_inputs_prepr['installment_factor'] = pd.cut(df_inputs_prepr['installment'], 50)\n",
        "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
        "df_temp = woe_ordered_continuous(df_inputs_prepr, 'installment_factor', df_targets_prepr)\n",
        "# We calculate weight of evidence.\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "6w1sISqZUidn",
        "outputId": "283e20b6-386a-4c04-e07f-3b0e72d0c434"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp, 90)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GQ1SpfZUxQG"
      },
      "source": [
        "##Part 2 Continuous Variables - Dummy Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PYWcDWD_V3WJ",
        "outputId": "72ededc1-7039-406d-d094-239c10b90cbd"
      },
      "outputs": [],
      "source": [
        "#after trial and error, we decideded to keep the income values equal and less than 140k. So we will apply 50 cuts.\n",
        "df_inputs_prepr_temp = df_inputs_prepr.loc[df_inputs_prepr['annual_inc'] <= 140000,:  ]\n",
        "df_inputs_prepr_temp ['annual_inc_factor'] = pd.cut(df_inputs_prepr_temp['annual_inc'],50)\n",
        "df_temp = woe_ordered_continuous (df_inputs_prepr_temp, 'annual_inc_factor', df_targets_prepr[df_inputs_prepr_temp.index])\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "eesEw4tFWUK2",
        "outputId": "6cfe62c4-e1ed-4c2f-806c-b9dbb1688f21"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp,90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "Y4W-e-N7WWZ2"
      },
      "outputs": [],
      "source": [
        "# WoE is monotonically decreasing with income, so we split income in 10 equal categories, each with width of 15k.\n",
        "df_inputs_prepr['annual_inc:<20K'] = np.where((df_inputs_prepr['annual_inc'] <= 20000), 1, 0)\n",
        "df_inputs_prepr['annual_inc:20K-30K'] = np.where((df_inputs_prepr['annual_inc'] > 20000) & (df_inputs_prepr['annual_inc'] <= 30000), 1, 0)\n",
        "df_inputs_prepr['annual_inc:30K-40K'] = np.where((df_inputs_prepr['annual_inc'] > 30000) & (df_inputs_prepr['annual_inc'] <= 40000), 1, 0)\n",
        "df_inputs_prepr['annual_inc:40K-50K'] = np.where((df_inputs_prepr['annual_inc'] > 40000) & (df_inputs_prepr['annual_inc'] <= 50000), 1, 0)\n",
        "df_inputs_prepr['annual_inc:50K-60K'] = np.where((df_inputs_prepr['annual_inc'] > 50000) & (df_inputs_prepr['annual_inc'] <= 60000), 1, 0)\n",
        "df_inputs_prepr['annual_inc:60K-70K'] = np.where((df_inputs_prepr['annual_inc'] > 60000) & (df_inputs_prepr['annual_inc'] <= 70000), 1, 0)\n",
        "df_inputs_prepr['annual_inc:70K-80K'] = np.where((df_inputs_prepr['annual_inc'] > 70000) & (df_inputs_prepr['annual_inc'] <= 80000), 1, 0)\n",
        "df_inputs_prepr['annual_inc:80K-90K'] = np.where((df_inputs_prepr['annual_inc'] > 80000) & (df_inputs_prepr['annual_inc'] <= 90000), 1, 0)\n",
        "df_inputs_prepr['annual_inc:90K-100K'] = np.where((df_inputs_prepr['annual_inc'] > 90000) & (df_inputs_prepr['annual_inc'] <= 100000), 1, 0)\n",
        "df_inputs_prepr['annual_inc:100K-120K'] = np.where((df_inputs_prepr['annual_inc'] > 100000) & (df_inputs_prepr['annual_inc'] <= 120000), 1, 0)\n",
        "df_inputs_prepr['annual_inc:120K-140K'] = np.where((df_inputs_prepr['annual_inc'] > 120000) & (df_inputs_prepr['annual_inc'] <= 140000), 1, 0)\n",
        "df_inputs_prepr['annual_inc:>140K'] = np.where((df_inputs_prepr['annual_inc'] > 140000), 1, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HrgqWuwOXOZZ",
        "outputId": "88a2e10a-2f4c-4d6e-9d0c-2b8033c85f4d"
      },
      "outputs": [],
      "source": [
        "# mths_since_last_delinq\n",
        "# We have to create one category for missing values and do fine and coarse classing for the rest.\n",
        "df_inputs_prepr_temp = df_inputs_prepr[pd.notnull(df_inputs_prepr['mths_since_last_delinq'])]\n",
        "df_inputs_prepr_temp['mths_since_last_delinq_factor'] = pd.cut(df_inputs_prepr_temp['mths_since_last_delinq'], 50)\n",
        "df_temp = woe_ordered_continuous(df_inputs_prepr_temp, 'mths_since_last_delinq_factor', df_targets_prepr[df_inputs_prepr_temp.index])\n",
        "# We calculate weight of evidence.\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "qBQWK8IOXQlG",
        "outputId": "c4781473-c9f8-4fe9-be82-bad21e7d9519"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp, 90)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "TSD_7oG2XRzi"
      },
      "outputs": [],
      "source": [
        "# Categories: Missing, 0-3, 4-30, 31-56, >=57\n",
        "df_inputs_prepr['mths_since_last_delinq:Missing'] = np.where((df_inputs_prepr['mths_since_last_delinq'].isnull()), 1, 0)\n",
        "df_inputs_prepr['mths_since_last_delinq:0-3'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 0) & (df_inputs_prepr['mths_since_last_delinq'] <= 3), 1, 0)\n",
        "df_inputs_prepr['mths_since_last_delinq:4-30'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 4) & (df_inputs_prepr['mths_since_last_delinq'] <= 30), 1, 0)\n",
        "df_inputs_prepr['mths_since_last_delinq:31-56'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 31) & (df_inputs_prepr['mths_since_last_delinq'] <= 56), 1, 0)\n",
        "df_inputs_prepr['mths_since_last_delinq:>=57'] = np.where((df_inputs_prepr['mths_since_last_delinq'] >= 57), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CYqvxnSRXeCf",
        "outputId": "2568b6ce-a04d-451f-c3f8-b72d541d4867"
      },
      "outputs": [],
      "source": [
        "# Similarly to income, initial examination shows that most values are lower than 35.\n",
        "# Hence, we are going to have one category for more than 35, and we are going to apply our approach to determine\n",
        "# the categories of everyone with 35 or less.\n",
        "df_inputs_prepr_temp = df_inputs_prepr.loc[df_inputs_prepr['dti'] <= 35, : ]\n",
        "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
        "df_inputs_prepr_temp['dti_factor'] = pd.cut(df_inputs_prepr_temp['dti'], 50)\n",
        "# We calculate weight of evidence.\n",
        "df_temp = woe_ordered_continuous(df_inputs_prepr_temp, 'dti_factor', df_targets_prepr[df_inputs_prepr_temp.index])\n",
        "\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "frWNe8YHXgXI",
        "outputId": "4fb7e00c-6a69-471b-9060-85030446ce8d"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp, 90)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKLD9u72XiTl"
      },
      "outputs": [],
      "source": [
        "# Categories:\n",
        "df_inputs_prepr['dti:<=1.4'] = np.where((df_inputs_prepr['dti'] <= 1.4), 1, 0)\n",
        "df_inputs_prepr['dti:1.4-3.5'] = np.where((df_inputs_prepr['dti'] > 1.4) & (df_inputs_prepr['dti'] <= 3.5), 1, 0)\n",
        "df_inputs_prepr['dti:3.5-7.7'] = np.where((df_inputs_prepr['dti'] > 3.5) & (df_inputs_prepr['dti'] <= 7.7), 1, 0)\n",
        "df_inputs_prepr['dti:7.7-10.5'] = np.where((df_inputs_prepr['dti'] > 7.7) & (df_inputs_prepr['dti'] <= 10.5), 1, 0)\n",
        "df_inputs_prepr['dti:10.5-16.1'] = np.where((df_inputs_prepr['dti'] > 10.5) & (df_inputs_prepr['dti'] <= 16.1), 1, 0)\n",
        "df_inputs_prepr['dti:16.1-20.3'] = np.where((df_inputs_prepr['dti'] > 16.1) & (df_inputs_prepr['dti'] <= 20.3), 1, 0)\n",
        "df_inputs_prepr['dti:20.3-21.7'] = np.where((df_inputs_prepr['dti'] > 20.3) & (df_inputs_prepr['dti'] <= 21.7), 1, 0)\n",
        "df_inputs_prepr['dti:21.7-22.4'] = np.where((df_inputs_prepr['dti'] > 21.7) & (df_inputs_prepr['dti'] <= 22.4), 1, 0)\n",
        "df_inputs_prepr['dti:22.4-35'] = np.where((df_inputs_prepr['dti'] > 22.4) & (df_inputs_prepr['dti'] <= 35), 1, 0)\n",
        "df_inputs_prepr['dti:>35'] = np.where((df_inputs_prepr['dti'] > 35), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1l7XaOA0XmdF",
        "outputId": "6ac7dd80-08e9-43b5-819e-bcf9c4a0eb74"
      },
      "outputs": [],
      "source": [
        "# mths_since_last_record\n",
        "# We have to create one category for missing values and do fine and coarse classing for the rest.\n",
        "df_inputs_prepr_temp = df_inputs_prepr[pd.notnull(df_inputs_prepr['mths_since_last_record'])]\n",
        "#sum(loan_data_temp['mths_since_last_record'].isnull())\n",
        "df_inputs_prepr_temp['mths_since_last_record_factor'] = pd.cut(df_inputs_prepr_temp['mths_since_last_record'], 50)\n",
        "# Here we do fine-classing: using the 'cut' method, we split the variable into 50 categories by its values.\n",
        "df_temp = woe_ordered_continuous(df_inputs_prepr_temp, 'mths_since_last_record_factor', df_targets_prepr[df_inputs_prepr_temp.index])\n",
        "# We calculate weight of evidence.\n",
        "df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "EJ7ZRlQIXoGm",
        "outputId": "53e017e7-3728-4ac1-cc8a-59d4ff5c2e74"
      },
      "outputs": [],
      "source": [
        "plot_by_woe(df_temp, 90)\n",
        "# We plot the weight of evidence values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_M1gFUMlXptL"
      },
      "outputs": [],
      "source": [
        "# Categories: 'Missing', '0-2', '3-20', '21-31', '32-80', '81-86', '>86'\n",
        "df_inputs_prepr['mths_since_last_record:Missing'] = np.where((df_inputs_prepr['mths_since_last_record'].isnull()), 1, 0)\n",
        "df_inputs_prepr['mths_since_last_record:0-2'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 0) & (df_inputs_prepr['mths_since_last_record'] <= 2), 1, 0)\n",
        "df_inputs_prepr['mths_since_last_record:3-20'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 3) & (df_inputs_prepr['mths_since_last_record'] <= 20), 1, 0)\n",
        "df_inputs_prepr['mths_since_last_record:21-31'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 21) & (df_inputs_prepr['mths_since_last_record'] <= 31), 1, 0)\n",
        "df_inputs_prepr['mths_since_last_record:32-80'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 32) & (df_inputs_prepr['mths_since_last_record'] <= 80), 1, 0)\n",
        "df_inputs_prepr['mths_since_last_record:81-86'] = np.where((df_inputs_prepr['mths_since_last_record'] >= 81) & (df_inputs_prepr['mths_since_last_record'] <= 86), 1, 0)\n",
        "df_inputs_prepr['mths_since_last_record:>=86'] = np.where((df_inputs_prepr['mths_since_last_record'] > 86), 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNH8qPaBYvY0"
      },
      "source": [
        "#6 Exporting CSV files - Preprocessed data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7KwnAKAd-wP"
      },
      "source": [
        "##a Exporting train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "Nu4Qq5sFXs-B"
      },
      "outputs": [],
      "source": [
        "#first run the code for the train and then test\n",
        "inputs_train = df_inputs_prepr\n",
        "inputs_train.to_csv('loan_data_inputs_train.csv')\n",
        "targets_train.to_csv('loan_data_targets_train.csv')\n",
        "#inputs_test = df_inputs_prepr\n",
        "#inputs_test.to_csv('loan_data_inputs_test.csv')\n",
        "#targets_test.to_csv('loan_data_targets_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhFjaFjAd9O4"
      },
      "source": [
        "##b Exporting test dataset\n",
        "\n",
        "Here we have two options to run preprocessing.\n",
        "\n",
        "Option 1:\n",
        "\n",
        " Either go to the code in '3c' and change df_inputs_prepr to inputs_test. Run all the codes above till down here.\n",
        "\n",
        "Option 2: \n",
        "\n",
        "  Use the python code on the src folder. Run the results with that.import sys #importing local functions in src folder\n",
        "sys.path.append('../src/')\n",
        "from functions import cross_validate_score, score_ML_log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzVDlQYxd8ke",
        "outputId": "c54dd372-d10d-47d9-ce4b-8ffe9a37e107"
      },
      "outputs": [],
      "source": [
        "#running preproc on test dataset\n",
        "inputs_test= preproc_input (inputs_test)\n",
        "inputs_test.columns.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "nDoeP_SbY2Mt"
      },
      "outputs": [],
      "source": [
        "inputs_test.to_csv('loan_data_inputs_test.csv')\n",
        "targets_train.to_csv('loan_data_targets_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GtUZUjNgrlP"
      },
      "source": [
        "--- End of Notebook ---\n",
        "#END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
