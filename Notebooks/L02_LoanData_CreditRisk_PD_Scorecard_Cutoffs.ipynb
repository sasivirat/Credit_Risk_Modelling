{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eRF4o5oDWICv"
      },
      "source": [
        "# Credit Risk Modeling | Part 2: PD Model w ML, Performances, Scorecard, Credit Score and Cutoffs\n",
        "\n",
        "<img src='https://salaamedia.com/wp-content/uploads/2022/07/Credit-Score.jpg'>  \n",
        "\n",
        "**Probability of default, PD**\n",
        "\n",
        "*  Logistic regression with the use of scikit learn library\n",
        "\n",
        "*  Probability of default means the likelihood that a borrower will default on debt (credit card, mortgage or non-mortgage loan) over a one-year period.In simple words, it returns the expected probability of customers fail to repay the loan. \n",
        "\n",
        "*  Probability is expressed in the form of percentage, lies between 0% and 100%. Higher the probability, higher the chance of default.\n",
        "\n",
        "\n",
        "**Scorecard**\n",
        "\n",
        "\n",
        "\n",
        "A scorecard needs to be easily interpretable by a layperson. It is a requirement imposed by the Basel Accord, almost all central banks, and various lending entities. Given the high monetary and non-monetary misclassification costs, it is achieved by a scorecard that use discretized variables even for any continuous variables. Therefore, differences between low and high scores can be easily explained to third parties.\n",
        "\n",
        "Our scorecard should have the minimum and maximum scores that are standardized. As a starting point, the score range of FICO is used from 300 to 850.\n",
        "\n",
        "Score cards have advantage of making the pd model coefficients more readable. So, let's convert pd model to score card\n",
        "\n",
        "**Loan Approval Cut-offs**\n",
        "\n",
        "What should be the loan cut-off point to decide whether to accept or reject loans? \n",
        "\n",
        "=> Borrowers with a credit score higher than the set cut-off point will be accepted for loans and those less than the cutoff point will be rejected? It serves as a fine balance between the expected loan approval and rejection rates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKXeGx0ikegP"
      },
      "source": [
        "# 1 Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j6DqIieWIC4"
      },
      "source": [
        "## a Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbPSxQTlQaWu",
        "outputId": "9268b6c2-0b52-4f73-f432-1f348201d183"
      },
      "outputs": [],
      "source": [
        "#installing gdown package to download dataset stored in G Drive\n",
        "!pip install gdown\n",
        "# to upgrade\n",
        "!pip install --upgrade gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KtnFrE1fWIC5"
      },
      "outputs": [],
      "source": [
        "#libs for managing data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#libs for ML regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics  \n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "#libs for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "#exporting ML model\n",
        "import pickle\n",
        "\n",
        "#lib to download dataset on g drive\n",
        "import gdown\n",
        "\n",
        "#setting display option max rows\n",
        "#pd.options.display.max_rows = None\n",
        "\n",
        "#importing custom-made functions\n",
        "import sys #importing local functions in src folder\n",
        "sys.path.append('../src/')\n",
        "from functions import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEsPU-_0O8Qg"
      },
      "source": [
        "## b Importing Preprocessed Test and Train Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d-p1JlcswJd"
      },
      "source": [
        "Please note that if you have already run the first notebook, you don't need to run the codes below and so download the data sets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ppaGS83Po_1",
        "outputId": "aad85050-a0f9-423e-9206-c40cb0c0a66c"
      },
      "outputs": [],
      "source": [
        "#test and train datasets were preprocessed in the first notebook.\n",
        "#they were than stocked over G-drive for the easiness. \n",
        "#the links below download those 4 files from G-Drive\n",
        "#Train dataset\n",
        "# 1st file \n",
        "# url = \"https://drive.google.com/file/d/1v45P0HhUxZ1x4HmD0bWblpUyUWuiC0_5/view?usp=share_link\"\n",
        "# output = \"loan_data_inputs_train.csv\"\n",
        "# g_down (url,'../data/'+output)\n",
        "\n",
        "# # 2nd file\n",
        "# url = \"https://drive.google.com/file/d/1KvP7EXfVNdekotGFqgp9UUlNXBLCKy9i/view?usp=share_link\"\n",
        "# output = \"loan_data_targets_train.csv\"\n",
        "# g_down (url,'../data/'+output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xA4nQaqOTqFS",
        "outputId": "29ca1a61-5742-418b-a3cb-34063d8a2828"
      },
      "outputs": [],
      "source": [
        "# Test dataset\n",
        "# 3rd file\n",
        "# url = \"https://drive.google.com/file/d/1M-VHZM612ihx-elO6dw3SVYJh0cWD5E6/view?usp=share_link\"\n",
        "# output = \"loan_data_inputs_test.csv\"\n",
        "# g_down (url,'../data/' + output)\n",
        "\n",
        "# # 4th file\n",
        "# url = \"https://drive.google.com/file/d/1wTkfTDyCxcMcddsz-Fk-AO_Y6owLhzWp/view?usp=share_link\"\n",
        "# output = \"loan_data_targets_test.csv\"\n",
        "# g_down (url,'../data/' + output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DZGGPyBLmKay"
      },
      "outputs": [],
      "source": [
        "# #loading csv files as pd dataframes\n",
        "# inputs_train = pd.read_csv ('../data/'+'loan_data_inputs_train.csv',index_col =0)\n",
        "# targets_train = pd.read_csv ('../data/'+'loan_data_targets_train.csv',index_col =0)\n",
        "# inputs_test = pd.read_csv ('../data/'+'loan_data_inputs_test.csv',index_col =0)\n",
        "# targets_test = pd.read_csv ('../data/'+'loan_data_targets_test.csv',index_col =0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq3fIlmPm6yY"
      },
      "source": [
        "## c Exploring Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doStfsNzSpYW",
        "outputId": "5f26639e-d6ca-4d4b-8767-993d79ea395e"
      },
      "outputs": [],
      "source": [
        "targets_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzKAikd9nHOj",
        "outputId": "b8cc993c-933b-4a47-cf9e-b63d39d32c95"
      },
      "outputs": [],
      "source": [
        "inputs_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwZOs0V-QazM",
        "outputId": "a0b07931-e191-466e-888b-227393c53d3f"
      },
      "outputs": [],
      "source": [
        "inputs_train.columns.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n0kIbGUnHD5",
        "outputId": "c066ffd5-b571-4b8e-b1e4-c04ffd849de1"
      },
      "outputs": [],
      "source": [
        "targets_test.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nocMf8xnG3S",
        "outputId": "f8de1b4d-a4bb-41c4-c290-dff5bdefa938"
      },
      "outputs": [],
      "source": [
        "inputs_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUs295KjQRlb",
        "outputId": "77809f69-d0c9-46b7-fb22-2cd0060b5980"
      },
      "outputs": [],
      "source": [
        "inputs_test.columns.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBHzLoTSnoIY"
      },
      "source": [
        "## d Avoiding dummy variable trap\n",
        "\n",
        "For each feature, dummy variables were created in data table. For example, for grades, we have 7 columns for Grades from Grade:A to Grade:G. Each column consists of values 1 or 0.  \n",
        "\n",
        "eg. for Grades=A, we use 0 Non and 1 True (Grade A)  \n",
        "We only need 7 - 1 columns in our prediction model. \n",
        "\n",
        "In this case, the reference category is Grade:D (see the first notebook).\n",
        "\n",
        "**We have to remove one dummy column for each original variable, to avoid falling into the dummy variable trap**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cgxHDe6sm4yx"
      },
      "outputs": [],
      "source": [
        "# Here we select a limited set of input variables                                           \n",
        "features_all = ['grade:A',\n",
        "'grade:B',\n",
        "'grade:C',\n",
        "'grade:D',\n",
        "'grade:E',\n",
        "'grade:F',\n",
        "'grade:G',\n",
        "'home_ownership:RENT_OTHER_NONE_ANY',\n",
        "'home_ownership:OWN',\n",
        "'home_ownership:MORTGAGE',\n",
        "'addr_state:ND_NE_IA_NV_FL_HI_AL',\n",
        "'addr_state:NM_VA',\n",
        "'addr_state:NY',\n",
        "'addr_state:OK_TN_MO_LA_MD_NC',\n",
        "'addr_state:CA',\n",
        "'addr_state:UT_KY_AZ_NJ',\n",
        "'addr_state:AR_MI_PA_OH_MN',\n",
        "'addr_state:RI_MA_DE_SD_IN',\n",
        "'addr_state:GA_WA_OR',\n",
        "'addr_state:WI_MT',\n",
        "'addr_state:TX',\n",
        "'addr_state:IL_CT',\n",
        "'addr_state:KS_SC_CO_VT_AK_MS',\n",
        "'addr_state:WV_NH_WY_DC_ME_ID',\n",
        "'verification_status:Not Verified',\n",
        "'verification_status:Source Verified',\n",
        "'verification_status:Verified',\n",
        "'purpose:educ__sm_b__wedd__ren_en__mov__house',\n",
        "'purpose:credit_card',\n",
        "'purpose:debt_consolidation',\n",
        "'purpose:oth__med__vacation',\n",
        "'purpose:major_purch__car__home_impr',\n",
        "'initial_list_status:f',\n",
        "'initial_list_status:w',\n",
        "'term:36',\n",
        "'term:60',\n",
        "'emp_length:0',\n",
        "'emp_length:1',\n",
        "'emp_length:2-4',\n",
        "'emp_length:5-6',\n",
        "'emp_length:7-9',\n",
        "'emp_length:10',\n",
        "'int_rate:<9.548',\n",
        "'int_rate:9.548-12.025',\n",
        "'int_rate:12.025-15.74',\n",
        "'int_rate:15.74-20.281',\n",
        "'int_rate:>20.281',\n",
        "'mths_since_earliest_cr_line:<140',\n",
        "'mths_since_earliest_cr_line:141-164',\n",
        "'mths_since_earliest_cr_line:165-247',\n",
        "'mths_since_earliest_cr_line:248-270',\n",
        "'mths_since_earliest_cr_line:271-352',\n",
        "'mths_since_earliest_cr_line:>352',\n",
        "'delinq_2yrs:0',\n",
        "'delinq_2yrs:1-3',\n",
        "'delinq_2yrs:>=4',\n",
        "'inq_last_6mths:0',\n",
        "'inq_last_6mths:1-2',\n",
        "'inq_last_6mths:3-6',\n",
        "'inq_last_6mths:>6',\n",
        "'open_acc:0',\n",
        "'open_acc:1-3',\n",
        "'open_acc:4-12',\n",
        "'open_acc:13-17',\n",
        "'open_acc:18-22',\n",
        "'open_acc:23-25',\n",
        "'open_acc:26-30',\n",
        "'open_acc:>=31',\n",
        "'pub_rec:0-2',\n",
        "'pub_rec:3-4',\n",
        "'pub_rec:>=5',\n",
        "'total_acc:<=27',\n",
        "'total_acc:28-51',\n",
        "'total_acc:>=52',\n",
        "'acc_now_delinq:0',\n",
        "'acc_now_delinq:>=1',\n",
        "'total_rev_hi_lim:<=5K',\n",
        "'total_rev_hi_lim:5K-10K',\n",
        "'total_rev_hi_lim:10K-20K',\n",
        "'total_rev_hi_lim:20K-30K',\n",
        "'total_rev_hi_lim:30K-40K',\n",
        "'total_rev_hi_lim:40K-55K',\n",
        "'total_rev_hi_lim:55K-95K',\n",
        "'total_rev_hi_lim:>95K',\n",
        "'annual_inc:<20K',\n",
        "'annual_inc:20K-30K',\n",
        "'annual_inc:30K-40K',\n",
        "'annual_inc:40K-50K',\n",
        "'annual_inc:50K-60K',\n",
        "'annual_inc:60K-70K',\n",
        "'annual_inc:70K-80K',\n",
        "'annual_inc:80K-90K',\n",
        "'annual_inc:90K-100K',\n",
        "'annual_inc:100K-120K',\n",
        "'annual_inc:120K-140K',\n",
        "'annual_inc:>140K',\n",
        "'dti:<=1.4',\n",
        "'dti:1.4-3.5',\n",
        "'dti:3.5-7.7',\n",
        "'dti:7.7-10.5',\n",
        "'dti:10.5-16.1',\n",
        "'dti:16.1-20.3',\n",
        "'dti:20.3-21.7',\n",
        "'dti:21.7-22.4',\n",
        "'dti:22.4-35',\n",
        "'dti:>35',\n",
        "'mths_since_last_delinq:Missing',\n",
        "'mths_since_last_delinq:0-3',\n",
        "'mths_since_last_delinq:4-30',\n",
        "'mths_since_last_delinq:31-56',\n",
        "'mths_since_last_delinq:>=57',\n",
        "'mths_since_last_record:Missing',\n",
        "'mths_since_last_record:0-2',\n",
        "'mths_since_last_record:3-20',\n",
        "'mths_since_last_record:21-31',\n",
        "'mths_since_last_record:32-80',\n",
        "'mths_since_last_record:81-86',\n",
        "'mths_since_last_record:>=86',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vsl7PxHroYse"
      },
      "outputs": [],
      "source": [
        "# Here we store the names of the reference category dummy variables in a list.\n",
        "ref_categories = ['grade:G',\n",
        "'home_ownership:RENT_OTHER_NONE_ANY',\n",
        "'addr_state:ND_NE_IA_NV_FL_HI_AL',\n",
        "'verification_status:Verified',\n",
        "'purpose:educ__sm_b__wedd__ren_en__mov__house',\n",
        "'initial_list_status:f',\n",
        "'term:60',\n",
        "'emp_length:0',\n",
        "'int_rate:>20.281',\n",
        "'mths_since_earliest_cr_line:<140',\n",
        "'delinq_2yrs:>=4',\n",
        "'inq_last_6mths:>6',\n",
        "'open_acc:0',\n",
        "'pub_rec:0-2',\n",
        "'total_acc:<=27',\n",
        "'acc_now_delinq:0',\n",
        "'total_rev_hi_lim:<=5K',\n",
        "'annual_inc:<20K',\n",
        "'dti:>35',\n",
        "'mths_since_last_delinq:0-3',\n",
        "'mths_since_last_record:0-2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "JBNRmnsAobFW",
        "outputId": "e5e724a4-7239-4072-fa2f-7bcdd6b5fbaa"
      },
      "outputs": [],
      "source": [
        "#loading values of df in a new dataframe.   \n",
        "inputs_train_ref_categories = inputs_train.loc[: ,features_all]\n",
        "# we drop the variables with reference categories.\n",
        "inputs_train_ref_categories = inputs_train_ref_categories.drop(ref_categories, axis = 1)\n",
        " \n",
        "inputs_train_ref_categories.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0dO9GNUtE2V9"
      },
      "source": [
        "# 2 Prediction of Default (PD) Model Fit with P-Values\n",
        "\n",
        "Logistic regression is considered for the PD model due to the Basel accord.\n",
        "\n",
        "Building a logistic regression model with P-Values\n",
        "\n",
        "\n",
        "**What is a p-value? How to use it to verify the relationship between variables**\n",
        "\n",
        "\"The p-value is, assuming that the null hypothesis is correct, the probability of obtaining results at least as extreme as the observed results of a statistical hypothesis test.\"  \n",
        "\n",
        "*The null hypothesis states that there is no relationship between the two variables being studied (one variable does not affect the other)*\n",
        "\n",
        "* When a relationship between two variables is set, there is always a possibility that this correlation might be a coincidence. \n",
        "* Checking p-value helps determine if the observed relationship is due to the result of chance or not.\n",
        "* A p-value is a statistical measurement used whether to validate or not a hypothesis against observed data.  \n",
        "* We use the p-value as an alternative to reject points to provide the smallest level of significance at which the null hypothesis would be rejected.  \n",
        "* A smaller p-value means that there is stronger evidence in favor of the alternative hypothesis. It means there is greater statistical significance of the observed difference.\n",
        "* A p-value of 0.05 or lower is generally considered statistically significant.\n",
        "\n",
        "Here is the strategy to evaluate the features:\n",
        "\n",
        "review p-values of all categories. if most of the dummy categories of a feature fall above a p-value of 0.05, eliminate them! p< 0.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APu3LUClrSPC"
      },
      "source": [
        "## a Model fit with p-values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Wax6ZtoaJJJD"
      },
      "outputs": [],
      "source": [
        "# Creating an instance from 'LogisticRegression_with_p_values()' class.\n",
        "reg = LogisticRegression_with_p_values()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vfXxUuAJTV5",
        "outputId": "cba17ddd-8151-45ed-a9b4-15460c3ee00c"
      },
      "outputs": [],
      "source": [
        "# Fitting and obtaining coefs \n",
        "reg.fit(inputs_train_ref_categories, targets_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fM6efOJpJfSY",
        "outputId": "a6dea140-8be4-4877-88f9-e493cc585d3b"
      },
      "outputs": [],
      "source": [
        "# creating a summary table\n",
        "feature_name = inputs_train_ref_categories.columns.values\n",
        "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
        "summary_table['Coefficients'] = np.transpose(reg.coef_)\n",
        "summary_table.index = summary_table.index + 1\n",
        "summary_table.loc[0] = ['Intercept', reg.intercept_[0]]\n",
        "summary_table = summary_table.sort_index()\n",
        "# We take the result of the newly added method 'p_values'\n",
        "p_values = reg.p_values\n",
        "# Adding the intercept for completeness. We add the value 'NaN' in the beginning of the variable with p-values.\n",
        "p_values = np.append(np.nan, np.array(p_values))\n",
        "# Adding a new column, called 'p_values', containing the values from the 'p_values' variable.\n",
        "summary_table['p_values'] = p_values\n",
        "\n",
        "summary_table"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GKuaeh0YawPV"
      },
      "source": [
        "Let's review the results  \n",
        "=> We can see that the following variables do not have much statistical significance:\n",
        "\n",
        "* mths_since_earliest_cr_line\n",
        "* delinq_2yrs\n",
        "* open_acc\n",
        "* total_acc\n",
        "* mths_since_last_delinq\n",
        "* mths_since_last_record"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMlz9Rl1rd4F"
      },
      "source": [
        "## b Model fit after removing some features based on p-values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "82mbBVAbJvhI"
      },
      "outputs": [],
      "source": [
        "# We commented on some features, the coefficients for all or almost all of the dummy variables for which,\n",
        "# are not statistically significant.\n",
        "# Refined variables\n",
        "features_all = ['grade:A',\n",
        "'grade:B',\n",
        "'grade:C',\n",
        "'grade:D',\n",
        "'grade:E',\n",
        "'grade:F',\n",
        "'grade:G',\n",
        "'home_ownership:RENT_OTHER_NONE_ANY',\n",
        "'home_ownership:OWN',\n",
        "'home_ownership:MORTGAGE',\n",
        "'addr_state:ND_NE_IA_NV_FL_HI_AL',\n",
        "'addr_state:NM_VA',\n",
        "'addr_state:NY',\n",
        "'addr_state:OK_TN_MO_LA_MD_NC',\n",
        "'addr_state:CA',\n",
        "'addr_state:UT_KY_AZ_NJ',\n",
        "'addr_state:AR_MI_PA_OH_MN',\n",
        "'addr_state:RI_MA_DE_SD_IN',\n",
        "'addr_state:GA_WA_OR',\n",
        "'addr_state:WI_MT',\n",
        "'addr_state:TX',\n",
        "'addr_state:IL_CT',\n",
        "'addr_state:KS_SC_CO_VT_AK_MS',\n",
        "'addr_state:WV_NH_WY_DC_ME_ID',\n",
        "'verification_status:Not Verified',\n",
        "'verification_status:Source Verified',\n",
        "'verification_status:Verified',\n",
        "'purpose:educ__sm_b__wedd__ren_en__mov__house',\n",
        "'purpose:credit_card',\n",
        "'purpose:debt_consolidation',\n",
        "'purpose:oth__med__vacation',\n",
        "'purpose:major_purch__car__home_impr',\n",
        "'initial_list_status:f',\n",
        "'initial_list_status:w',\n",
        "'term:36',\n",
        "'term:60',\n",
        "'emp_length:0',\n",
        "'emp_length:1',\n",
        "'emp_length:2-4',\n",
        "'emp_length:5-6',\n",
        "'emp_length:7-9',\n",
        "'emp_length:10',\n",
        "'int_rate:<9.548',\n",
        "'int_rate:9.548-12.025',\n",
        "'int_rate:12.025-15.74',\n",
        "'int_rate:15.74-20.281',\n",
        "'int_rate:>20.281',\n",
        "#'mths_since_earliest_cr_line:<140',\n",
        "#'mths_since_earliest_cr_line:141-164',\n",
        "#'mths_since_earliest_cr_line:165-247',\n",
        "#'mths_since_earliest_cr_line:248-270',\n",
        "#'mths_since_earliest_cr_line:271-352',\n",
        "#'mths_since_earliest_cr_line:>352',\n",
        "#'delinq_2yrs:0',\n",
        "#'delinq_2yrs:1-3',\n",
        "#'delinq_2yrs:>=4',\n",
        "'inq_last_6mths:0',\n",
        "'inq_last_6mths:1-2',\n",
        "'inq_last_6mths:3-6',\n",
        "'inq_last_6mths:>6',\n",
        "#'open_acc:0',\n",
        "#'open_acc:1-3',\n",
        "#'open_acc:4-12',\n",
        "#'open_acc:13-17',\n",
        "#'open_acc:18-22',\n",
        "#'open_acc:23-25',\n",
        "#'open_acc:26-30',\n",
        "#'open_acc:>=31',\n",
        "'pub_rec:0-2',\n",
        "'pub_rec:3-4',\n",
        "'pub_rec:>=5',\n",
        "#'total_acc:<=27',\n",
        "#'total_acc:28-51',\n",
        "#'total_acc:>=52',\n",
        "'acc_now_delinq:0',\n",
        "'acc_now_delinq:>=1',\n",
        "'total_rev_hi_lim:<=5K',\n",
        "'total_rev_hi_lim:5K-10K',\n",
        "'total_rev_hi_lim:10K-20K',\n",
        "'total_rev_hi_lim:20K-30K',\n",
        "'total_rev_hi_lim:30K-40K',\n",
        "'total_rev_hi_lim:40K-55K',\n",
        "'total_rev_hi_lim:55K-95K',\n",
        "'total_rev_hi_lim:>95K',\n",
        "'annual_inc:<20K',\n",
        "'annual_inc:20K-30K',\n",
        "'annual_inc:30K-40K',\n",
        "'annual_inc:40K-50K',\n",
        "'annual_inc:50K-60K',\n",
        "'annual_inc:60K-70K',\n",
        "'annual_inc:70K-80K',\n",
        "'annual_inc:80K-90K',\n",
        "'annual_inc:90K-100K',\n",
        "'annual_inc:100K-120K',\n",
        "'annual_inc:120K-140K',\n",
        "'annual_inc:>140K',\n",
        "'dti:<=1.4',\n",
        "'dti:1.4-3.5',\n",
        "'dti:3.5-7.7',\n",
        "'dti:7.7-10.5',\n",
        "'dti:10.5-16.1',\n",
        "'dti:16.1-20.3',\n",
        "'dti:20.3-21.7',\n",
        "'dti:21.7-22.4',\n",
        "'dti:22.4-35',\n",
        "'dti:>35',\n",
        "#'mths_since_last_delinq:Missing',\n",
        "#'mths_since_last_delinq:0-3',\n",
        "#'mths_since_last_delinq:4-30',\n",
        "#'mths_since_last_delinq:31-56',\n",
        "#'mths_since_last_delinq:>=57',\n",
        "#'mths_since_last_record:Missing',\n",
        "#'mths_since_last_record:0-2',\n",
        "#'mths_since_last_record:3-20',\n",
        "#'mths_since_last_record:21-31',\n",
        "#'mths_since_last_record:32-80',\n",
        "#'mths_since_last_record:81-86',\n",
        "#'mths_since_last_record:>=86',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lW76hHl4KB5K"
      },
      "outputs": [],
      "source": [
        "ref_categories = ['grade:G',\n",
        "'home_ownership:RENT_OTHER_NONE_ANY',\n",
        "'addr_state:ND_NE_IA_NV_FL_HI_AL',\n",
        "'verification_status:Verified',\n",
        "'purpose:educ__sm_b__wedd__ren_en__mov__house',\n",
        "'initial_list_status:f',\n",
        "'term:60',\n",
        "'emp_length:0',\n",
        "'int_rate:>20.281',\n",
        "#'mths_since_earliest_cr_line:<140',\n",
        "#'delinq_2yrs:>=4',\n",
        "'inq_last_6mths:>6',\n",
        "#'open_acc:0',\n",
        "'pub_rec:0-2',\n",
        "#'total_acc:<=27',\n",
        "'acc_now_delinq:0',\n",
        "'total_rev_hi_lim:<=5K',\n",
        "'annual_inc:<20K',\n",
        "'dti:>35'\n",
        "#'mths_since_last_delinq:0-3',\n",
        "#'mths_since_last_record:0-2'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "Iu2LX7VDKCPK",
        "outputId": "3d05992a-47e0-454c-a1e0-0b43a1758b8e"
      },
      "outputs": [],
      "source": [
        "#loading values of df in a new dataframe.   \n",
        "inputs_train_ref_categories = inputs_train.loc[: , features_all]\n",
        "\n",
        "# we drop the variables with reference categories.\n",
        "inputs_train_ref_categories = inputs_train_ref_categories.drop(ref_categories, axis = 1)\n",
        " \n",
        "inputs_train_ref_categories.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNo0u7acuTmp",
        "outputId": "d71d09ca-91f4-455d-fc4c-179208061419"
      },
      "outputs": [],
      "source": [
        "inputs_train_ref_categories.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJJsYbmWuVz7",
        "outputId": "5e25046a-a47c-4e82-cb92-cfbbffa63cca"
      },
      "outputs": [],
      "source": [
        "targets_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctp2YsSMKF-G",
        "outputId": "a9b3b094-4a6a-4708-c321-deb97f870874"
      },
      "outputs": [],
      "source": [
        "# Here we run a new model.\n",
        "reg2 = LogisticRegression_with_p_values()\n",
        "reg2.fit(inputs_train_ref_categories, targets_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "h0kPC6fDKRQh",
        "outputId": "4f1cda85-5afd-4c4f-f0d2-e5f2f83f0126"
      },
      "outputs": [],
      "source": [
        "# Same as above.\n",
        "feature_name = inputs_train_ref_categories.columns.values\n",
        "summary_table = pd.DataFrame(columns = ['Feature name'], data = feature_name)\n",
        "summary_table['Coefficients'] = np.transpose(reg2.coef_)\n",
        "summary_table.index = summary_table.index + 1\n",
        "summary_table.loc[0] = ['Intercept', reg2.intercept_[0]]\n",
        "summary_table = summary_table.sort_index()\n",
        "summary_table\n",
        "\n",
        "# We add the 'p_values' here, just as we did before.\n",
        "p_values = reg2.p_values\n",
        "p_values = np.append(np.nan,np.array(p_values))\n",
        "summary_table['p_values'] = p_values\n",
        "summary_table\n",
        "# Here we get the results for our final PD model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43g5lmrCzKXH"
      },
      "source": [
        "## c Dumping trained PD model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3r0ZnHQUKZzk"
      },
      "outputs": [],
      "source": [
        "# Here we export our model to a 'sav' file\n",
        "pickle.dump(reg2, open('../models/'+'pd_model.sav', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0e69Mf1WaVY"
      },
      "source": [
        "## d PD Model Validation on Test Dataset - Out of sample validation (test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "U-LI3Rgj2dDV",
        "outputId": "d6d033f6-bd31-456a-d5e9-ef403c5d48d0"
      },
      "outputs": [],
      "source": [
        "#loading df with features refined.   \n",
        "inputs_test_ref_categories = inputs_test.loc[: , features_all]\n",
        "\n",
        "# we drop the variables with reference categories.\n",
        "inputs_test_ref_categories = inputs_test_ref_categories.drop(ref_categories, axis = 1)\n",
        " \n",
        "inputs_test_ref_categories.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe-8CkGhWvNW",
        "outputId": "e5ea6f1b-9a90-4b1b-a782-ba6fddf56e2a"
      },
      "outputs": [],
      "source": [
        "# Calculating the predicted values for test data set\n",
        "# based on the values of the independent variables\n",
        "y_hat_test = reg2.model.predict(inputs_test_ref_categories)\n",
        "# calculating class probabilities for all classes\n",
        "y_hat_test_proba = reg2.model.predict_proba(inputs_test_ref_categories)\n",
        "\n",
        "# an array of predicted discrete classess  (0s and 1s).\n",
        "y_hat_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urD0xYj6W6Li",
        "outputId": "50344bb2-a11e-40b8-cfc1-c1e2a4f12779"
      },
      "outputs": [],
      "source": [
        "# first value of every sub-array is the probability for the observation to belong \n",
        "# to the first class, i.e. 0,\n",
        "#the second value is the probability for the observation to belong to the first class, i.e. 1.\n",
        "y_hat_test_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "054IfuHCW6BJ",
        "outputId": "9368c93b-cd04-46f3-8550-037731cb2f51"
      },
      "outputs": [],
      "source": [
        "# We store these probabilities of 1 (good) in a variable.\n",
        "y_hat_test_proba = y_hat_test_proba[: ][: , 1]\n",
        "\n",
        "# Array of probabilities of being 1.\n",
        "y_hat_test_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Lq1HYGj-W58V"
      },
      "outputs": [],
      "source": [
        "targets_test_temp = targets_test\n",
        "\n",
        "# Reseting the index of a dataframe.\n",
        "targets_test_temp.reset_index(drop = True, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkgIECV9W50Z",
        "outputId": "3f855f19-72bd-43fa-ac50-8d09e137207c"
      },
      "outputs": [],
      "source": [
        "# Concatenating two dataframes consists of actual and predicted results\n",
        "df_actual_predicted_probs = pd.concat([targets_test_temp, pd.DataFrame(y_hat_test_proba)], axis = 1)\n",
        "\n",
        "df_actual_predicted_probs.columns = ['targets_test', 'y_hat_test_proba']\n",
        "df_actual_predicted_probs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "I_p9iiHVW5qT",
        "outputId": "44961a72-7ca3-4db3-9666-b9e42cac4405"
      },
      "outputs": [],
      "source": [
        "# Making the index of one dataframe equal to the index of another dataframe.\n",
        "df_actual_predicted_probs.index = inputs_test.index\n",
        "\n",
        "df_actual_predicted_probs.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2LfIdiCFxLI"
      },
      "source": [
        "# 3 Evaluation of Model Performances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDOblGIGXQTM"
      },
      "source": [
        "## a Calculation of Accuracy\n",
        "\n",
        "Accuracy is the fraction of predictions our model predicted correctly.\n",
        "\n",
        "It should be noted that accuracy alone is not sufficient when we are working with a class-imbalanced data set and where there is a significant difference between the number of positive and negative labels.\n",
        "\n",
        "In this case, we also define the threshold as 0.9 to say whether or not to accept a loan request."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yLdNug_GXP7l"
      },
      "outputs": [],
      "source": [
        "# We create a new column with an indicator,\n",
        "# where every observation that has predicted probability greater than the threshold has a value of 1,\n",
        "# and every observation that has predicted probability lower than the threshold has a value of 0.\n",
        "tr = 0.9\n",
        "\n",
        "df_actual_predicted_probs['y_hat_test'] = np.where(df_actual_predicted_probs['y_hat_test_proba'] > tr, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "Ee1PNLSrXZb1",
        "outputId": "4af3615c-197a-4016-ee93-17765cf2261f"
      },
      "outputs": [],
      "source": [
        "# Creating a cross-table, aka a Confusion Matrix\n",
        "# Actual values are displayed by rows and the predicted values by columns.\n",
        "confusion_matrix = pd.crosstab(df_actual_predicted_probs['targets_test'],\\\n",
        "            df_actual_predicted_probs['y_hat_test'], rownames = ['Actual'],\\\n",
        "            colnames = ['Predicted'])\n",
        "confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wCkjxWZB_yR"
      },
      "source": [
        "Breakdown of results\n",
        "\n",
        "| True Negatives  | False Negatives |  \n",
        "| False Positives | True Positives  |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "SSCP91FSXZSL",
        "outputId": "0d99693c-0d14-4367-f647-fa8c72459b50"
      },
      "outputs": [],
      "source": [
        "# Let's divide each value of the table by the total number of observations,\n",
        "# Getting percentages, or, rates.\n",
        "confusionm_perc = confusion_matrix/ df_actual_predicted_probs.shape[0]\n",
        "confusionm_perc           "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpbJArrsXZE4",
        "outputId": "78c8c680-d914-413f-98b9-d9ae760316a9"
      },
      "outputs": [],
      "source": [
        "# Then we calculate the accuracy of the model: sum of the diagonal ratios. on test dataset\n",
        "\n",
        "TN = confusionm_perc.iloc[0, 0] #true negative\n",
        "TP = confusionm_perc.iloc[1, 1] #true positive\n",
        "print('Accuracy on test dataset=', round(TN + TP,4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv2aU4rQ_r7c"
      },
      "source": [
        "57% of the time, the model predicted correctly whether or not the borrower will default for a set threshold of 0.9.\n",
        "\n",
        "It means that the model makes bad estimations 43% of the time. 3% of the time, it fails predicting default (bad) cases.  40% of the time it fails predicting good cases where the borrower did not default. \n",
        "\n",
        "In point of view of the bank, the results are overconservative and reduce the risk of money lost due to the borrower being defaulted. \n",
        "\n",
        "This may bring the problem of a bank losing customers as the model fails giving credits to some GOOD borrowers.\n",
        "\n",
        "**Is it good enough?**\n",
        "\n",
        "=> For this example case, we do not go further to tweak the scores. The optimal is to reduce the false negatives (priority) and false positives.\n",
        "*Let's go further to investigate the model performance.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAk-mSJh9HZS"
      },
      "source": [
        "## b Area Under ROC\n",
        "\n",
        "Receiver Operating Characteristic= ROC\n",
        "\n",
        "Area under curve (AUC) plots the True Positive Rates against False Positive Rates at various threshold values. It can separate the ‘signal’ from the ‘noise’. It is used to measure the ability of a classifier to differentiate between classes.\n",
        "\n",
        "AUC ranges in value from 0 to 1. The higher the AUC, the better the performance of the model at distinguishing between the P and N classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "orequvW4XmbY"
      },
      "outputs": [],
      "source": [
        "# Obtaining Receiver Operating Characteristic (ROC) Curve from a set of actual values \n",
        "# and their predicted probabilities.\n",
        "# As a result, we get three arrays: the false positive rates, the true positive rates, \n",
        "# and the thresholds.\n",
        "# we store each of the three arrays in a separate variable. \n",
        "fpr, tpr, thresholds = roc_curve(df_actual_predicted_probs['targets_test'],\\\n",
        "          df_actual_predicted_probs['y_hat_test_proba'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "RDsdfB1gXl_W",
        "outputId": "558e602d-6a40-48ac-af69-5a800f5b5b73"
      },
      "outputs": [],
      "source": [
        "# Plotting the ROC curve herein\n",
        "# false positive rate along the x-axis and the true positive rate along the y-axis,\n",
        "plt.plot(fpr, tpr)\n",
        "# Plotting a diagonal line, with dashed line style and black color.\n",
        "plt.plot(fpr, fpr, linestyle = '--', color = 'k')\n",
        "# relabeling the axes\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTnmYcARXtqL",
        "outputId": "ea1e317d-070d-4467-d89c-775d7b2dd458"
      },
      "outputs": [],
      "source": [
        "# Calculating AUROC from a set of actual values and their predicted probabilities.\n",
        "AUROC = roc_auc_score(df_actual_predicted_probs['targets_test'],\\\n",
        "                      df_actual_predicted_probs['y_hat_test_proba'])\n",
        "AUROC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIbov5XG90av"
      },
      "source": [
        "So, we found 0.68. It is above 0.50 so it shows a better performance of 1:1 line, a dummy model of probability of 0.50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9m2L_-LUfnp"
      },
      "source": [
        "## c Gini coefficient\n",
        "\n",
        "Gini Index, aka Gini impurity, calculates the amount of probability of a specific feature that is classified incorrectly when randomly selected.\n",
        "\n",
        "Gini index varies between values 0 and 1.  \n",
        "Gini index of 0 =  the purity of classification. Each element belongs to a specified class or only one class exists there.  \n",
        "Gini index of 1 = the random distribution of elements across various classes. \n",
        "\n",
        "The value of 0.5 of the Gini Index shows an equal distribution of elements over some classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "j1z8CVHtKbNW"
      },
      "outputs": [],
      "source": [
        "#sorting proba values and resetting index\n",
        "df_actual_predicted_probs = df_actual_predicted_probs.sort_values('y_hat_test_proba')\n",
        "df_actual_predicted_probs = df_actual_predicted_probs.reset_index()\n",
        "# calculating cumulative pop, good and bad\n",
        "df_actual_predicted_probs['Cum N Population'] = df_actual_predicted_probs.index + 1\n",
        "df_actual_predicted_probs['Cum N Good'] = df_actual_predicted_probs['targets_test'].cumsum()\n",
        "df_actual_predicted_probs['Cum N Bad'] = df_actual_predicted_probs['Cum N Population']\\\n",
        "                                        - df_actual_predicted_probs['Cum N Good']\n",
        "# Calculating the cumulative percentage of all, good, and bad observations.\n",
        "sum_all= df_actual_predicted_probs.shape[0]\n",
        "df_actual_predicted_probs['Cum Perc Population'] = df_actual_predicted_probs['Cum N Population'] / sum_all\n",
        "# Calculating cumulative percentage of 'good'.\n",
        "sum_good=  df_actual_predicted_probs['targets_test'].sum()\n",
        "df_actual_predicted_probs['Cum Perc Good'] = df_actual_predicted_probs['Cum N Good'] /sum_good\n",
        "# Calculating the cumulative percentage of 'bad'.\n",
        "sum_bad = sum_all- sum_good\n",
        "df_actual_predicted_probs['Cum Perc Bad'] = df_actual_predicted_probs['Cum N Bad'] / sum_bad\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TBMAHjgJVJVt",
        "outputId": "2fc70220-1aff-4404-9cff-c2a85f5f2016"
      },
      "outputs": [],
      "source": [
        "df_actual_predicted_probs.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_BfbuCUXX0cu",
        "outputId": "a94151c9-d18c-43f6-9e37-bbc77dab34a3"
      },
      "outputs": [],
      "source": [
        "df_actual_predicted_probs.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9EKlPZzhZLzk",
        "outputId": "8e93ac7c-b80c-47e7-967f-b45e79ca4aed"
      },
      "outputs": [],
      "source": [
        "# Plotting Gini - cumulative percentage versus the cumulative percentage 'good' along the y-axis\n",
        "plt.plot(df_actual_predicted_probs['Cum Perc Population'], df_actual_predicted_probs['Cum Perc Bad'])\n",
        "# Plotting a seconary diagonal line, with dashed line style and black color.\n",
        "plt.plot(df_actual_predicted_probs['Cum Perc Population'], df_actual_predicted_probs['Cum Perc Population'], linestyle = '--', color = 'k')\n",
        "# Relabelling \n",
        "plt.xlabel('Cumulative % Population')\n",
        "plt.ylabel('Cumulative % Bad')\n",
        "plt.title('Gini')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgIEEe7kZObJ",
        "outputId": "14d8c1e4-cfa1-42c8-c703-e686dcc1dd4e"
      },
      "outputs": [],
      "source": [
        "# Here we calculate Gini from AUROC.\n",
        "Gini = AUROC * 2 - 1\n",
        "Gini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp9pRLWOKLYz"
      },
      "source": [
        "The Gini coefficient is a ratio showing that\n",
        "\n",
        "*  how close our model to be a “perfect model\" (a Gini coef of 1)\n",
        "*  how far our model to be from being a “random model” (a Gini coefficient of 0)\n",
        "\n",
        "The GINI score of 0.37 shows that it can be improved by better building the PD model. For this example, we keep the model as it is. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j5oV2VwFmHn"
      },
      "source": [
        "## d Kolmogorov-Smirnov coefficient\n",
        "\n",
        "Kolomogrov-Smirnov (KS) coefficient evaluates the separation between class distributions.\n",
        "\n",
        "KS statistics for two samples is simply the greatest distance between two cumulative distribution functions of the positive and negative class distributions. Similar to Gini coefficient, we can have another metric to evaluate classifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2lu_djIOZSOt",
        "outputId": "dd2f501c-6350-455b-e453-0a35c051efe7"
      },
      "outputs": [],
      "source": [
        "# Plotting KS \n",
        "# 1 predicted (estimated) probabilities versus the cumulative percentage 'bad' along the y-axis,\n",
        "plt.plot(df_actual_predicted_probs['y_hat_test_proba'], df_actual_predicted_probs['Cum Perc Bad'], color = 'r')\n",
        "# 2 predicted (estimated) probabilities versus the cumulative percentage 'good' along the y-axis,\n",
        "plt.plot(df_actual_predicted_probs['y_hat_test_proba'], df_actual_predicted_probs['Cum Perc Good'], color = 'b')\n",
        "# relabelling\n",
        "plt.xlabel('Estimated Probability for being Good')\n",
        "plt.ylabel('Cumulative %')\n",
        "plt.title('Kolmogorov-Smirnov')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikhf7KzOZWUC",
        "outputId": "6a6e0dc3-453e-4c77-c0ed-25498c8e6b04"
      },
      "outputs": [],
      "source": [
        "# Calculating KS from the data. \n",
        "# Max difference between the cumulative percentage of 'bad' and 'good'\n",
        "KS = max(df_actual_predicted_probs['Cum Perc Bad'] - df_actual_predicted_probs['Cum Perc Good'])\n",
        "KS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMonXTTqa-Up"
      },
      "source": [
        "# 4 Applying PD model for decision making\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjGaV7vQch8N"
      },
      "source": [
        "## a Creating scorecard\n",
        "\n",
        "calculating credit worthiness - credit scores based on our PD model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sSqU926uc2gI",
        "outputId": "a591554a-2f6c-4b4d-f36f-9df08a1c284a"
      },
      "outputs": [],
      "source": [
        "df_ref_categories = pd.DataFrame(ref_categories,columns = ['Feature name'])\n",
        "df_ref_categories['Coefficients'] = 0\n",
        "df_ref_categories['p_values'] = np.nan\n",
        "\n",
        "df_scorecard = pd.concat ([summary_table, df_ref_categories ])\n",
        "df_scorecard = df_scorecard.reset_index()\n",
        "\n",
        "df_scorecard['Original feature name'] = df_scorecard['Feature name'].str.split(':').str[0]\n",
        "df_scorecard.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Z2ehrpHDdohW"
      },
      "outputs": [],
      "source": [
        "#let's say we fix minimum score of 300 and max score of 850\n",
        "min_score = 300\n",
        "max_score = 850"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "4Amxl6W9e-as",
        "outputId": "cde82448-54e6-4f2d-d4ed-a446cee4c316"
      },
      "outputs": [],
      "source": [
        "#determining the ratio to multiply with the coefficients so that \n",
        "# min_score is equal to 300 and max_score is equal to 850\n",
        "max_sum_coef = df_scorecard.groupby('Original feature name')['Coefficients'].max().sum()\n",
        "min_sum_coef = df_scorecard.groupby('Original feature name')['Coefficients'].min().sum()\n",
        "ratio_ = (max_score-min_score) / (max_sum_coef - min_sum_coef)\n",
        "#calculating scores from coefs\n",
        "df_scorecard['Score - Calculation'] = df_scorecard['Coefficients'] * ratio_\n",
        "#replacing intercept coef\n",
        "df_scorecard['Score - Calculation'][0] = (df_scorecard['Coefficients'][0] -\\\n",
        "                                           min_sum_coef)*ratio_+ min_score\n",
        "#rounding the scores to integer like\n",
        "df_scorecard['Score - Preliminary'] = df_scorecard['Score - Calculation'].round()\n",
        "df_scorecard.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-oSjgKwUMo-",
        "outputId": "44f3c5f9-65bb-4e38-c8af-eb049b391bbf"
      },
      "outputs": [],
      "source": [
        "#let's check if we have min score of 300 and max score of 800\n",
        "min_sum_score_prel = df_scorecard.groupby('Original feature name')['Score - Preliminary'].min().sum()\n",
        "#let's check if we have min score of 300 and max score of 800\n",
        "max_sum_score_prel = df_scorecard.groupby('Original feature name')['Score - Preliminary'].max().sum()\n",
        "print(min_sum_score_prel, max_sum_score_prel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVbBEMsdb-Ig"
      },
      "source": [
        "Max score is 849. We need to alter and increase one of the scores by 1 pt. Let's print out the values rounded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "PdwoCLGydWwL",
        "outputId": "bbbc1f10-2fcc-4307-bc25-1c6d5f3d86fc"
      },
      "outputs": [],
      "source": [
        "df_scorecard['Score - Final'] = df_scorecard['Score - Preliminary']\n",
        "#let's check which index value to increase\n",
        "df_scorecard['Difference'] =  df_scorecard['Score - Preliminary'] - df_scorecard['Score - Calculation']\n",
        "#let's print out the max scores of each feature\n",
        "df_scorecard.loc[df_scorecard.groupby(['Original feature name'])['Score - Final'].idxmax()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1RQkDXahVER",
        "outputId": "56e7a827-1e67-4a1c-83fb-91c2235b1791"
      },
      "outputs": [],
      "source": [
        "#increasing the rounded score of some features 1+ to have max score of 850 at the end\n",
        "df_scorecard['Score - Final'][21]  = 39 #coef will be adjusted one pt higher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY7z1YToiqUV",
        "outputId": "df74f149-fcef-4189-baa0-f4a1deaa19b4"
      },
      "outputs": [],
      "source": [
        "#let's check if we have min score of 300 and max score of 800\n",
        "min_sum_score_prel = df_scorecard.groupby('Original feature name')['Score - Final'].min().sum()\n",
        "min_sum_score_prel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrTNippIisYY",
        "outputId": "394f7e22-50bf-41fc-8935-ae7d7a156b2f"
      },
      "outputs": [],
      "source": [
        "#let's check if we have min score of 300 and max score of 800\n",
        "max_sum_score_prel = df_scorecard.groupby('Original feature name')['Score - Final'].max().sum()\n",
        "max_sum_score_prel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK0Jo2LJi975"
      },
      "source": [
        "**We finally have a min score of 300 and a max score of 850.**\n",
        "\n",
        "Score card is ready!!! Let's Export It"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ebkRrV1irC6_"
      },
      "outputs": [],
      "source": [
        "inputs_test_ref_categories.to_csv('../data/inputs_train_with_ref_categories.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "DPEXsyWtgVih"
      },
      "outputs": [],
      "source": [
        "df_scorecard.to_csv('../data/df_scorecard.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTAuFg8RnvQ5"
      },
      "source": [
        "##b Calculating Credit Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "JASXtUB97P9C",
        "outputId": "5c7c92f9-860a-468c-ec67-6c2e1b340eca"
      },
      "outputs": [],
      "source": [
        "inputs_test_ref_categories.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mVU7eSVpJSO",
        "outputId": "3e613fa8-02e8-48c6-80f2-719850533d1d"
      },
      "outputs": [],
      "source": [
        "# test dataset with reference categories\n",
        "inputs_test_with_ref_cat_w_intercept = inputs_train.loc[: , features_all]\n",
        "# inserting the intercept point w an index of 0, that is, in the beginning of df\n",
        "# The name of that column is 'Intercept', and its values are 1s.\n",
        "inputs_test_with_ref_cat_w_intercept.insert(0,'Intercept', 1)\n",
        "# ensuring that we selected the same features used in scorecard \n",
        "inputs_test_with_ref_cat_w_intercept = inputs_test_with_ref_cat_w_intercept [df_scorecard['Feature name'].values]\n",
        "\n",
        "inputs_test_with_ref_cat_w_intercept.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOg6n1cM-ALx",
        "outputId": "1220a039-9362-4305-eaa2-127660d1cf04"
      },
      "outputs": [],
      "source": [
        "#creating the score card array\n",
        "scorecard_scores = df_scorecard['Score - Final']\n",
        "scorecard_scores.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "r9ZmR1eCpg6x"
      },
      "outputs": [],
      "source": [
        "#from list to an array\n",
        "scorecard_scores = scorecard_scores.values.reshape(87,1)\n",
        "# multiplying the values of each row of the dataframe by the values of each column of the variable,\n",
        "# with 'dot' method (sum of the products)\n",
        "y_scores = inputs_test_with_ref_cat_w_intercept.dot(scorecard_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FNE-lHbJrDW_",
        "outputId": "fd95ffbc-0d0a-43ac-f40d-37291bef91bf"
      },
      "outputs": [],
      "source": [
        "y_scores.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6PCqmOnrb-g"
      },
      "source": [
        "##c From Credit Score to Probability of Default\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "swbaHOL_rE7_",
        "outputId": "d233e884-3bd7-4b04-c52b-cf0cb9db1a2e"
      },
      "outputs": [],
      "source": [
        "# Dividing the difference b/w the scores and the minimum score by diff b/w max and min score.\n",
        "# Multiplying by the diff b/w max sum of coefs and min sum of coefs.\n",
        "# Adding minimum sum of coefs.\n",
        "coef_ =   (max_sum_coef - min_sum_coef) / (max_score - min_score) \n",
        "sum_coef_from_score = (y_scores - min_score) * coef_ + min_sum_coef\n",
        "# dividing an exponent raised to sum of coefs from score by\n",
        "# an exponent raised to sum of coefs from score plus one.\n",
        "y_hat_proba_from_score = np.exp(sum_coef_from_score) / (np.exp(sum_coef_from_score) + 1)\n",
        "y_hat_proba_from_score.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkxPWOSYd1Ou"
      },
      "source": [
        "##d Setting CutOffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "zgvpKCDynWFO"
      },
      "outputs": [],
      "source": [
        "# Getting ROC Curve and their predicted probabilities.\n",
        "# It returns us the false positive rates, the true positive rates, and the thresholds.\n",
        "fpr, tpr, thresholds = roc_curve(df_actual_predicted_probs['targets_test'],\\\n",
        "          df_actual_predicted_probs['y_hat_test_proba'])\n",
        "# Conconating 3 dataframes along the columns.\n",
        "df_cutoffs = pd.concat([pd.DataFrame(thresholds), pd.DataFrame(fpr), pd.DataFrame(tpr)], axis = 1)\n",
        "# Naming the columns of the dataframe 'thresholds', 'fpr', and 'tpr'.\n",
        "df_cutoffs.columns = ['thresholds', 'fpr', 'tpr']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "fSTVmnKVspXc"
      },
      "outputs": [],
      "source": [
        "# Let the 1st threshold (the value of the thresholds column with index 0) be equal \n",
        "# very close to 1 but smaller than 1\n",
        "df_cutoffs['thresholds'][0] = 1 - 1 / np.power(10, 20)\n",
        "\n",
        "# The score corresponding to each threshold equals:\n",
        "ratio_ = (max_score-min_score) / (max_sum_coef - min_sum_coef)\n",
        "df_cutoffs['Score'] = ((np.log(df_cutoffs['thresholds'] / (1 - df_cutoffs['thresholds'])) - min_sum_coef) * ratio_ + min_score).round()\n",
        "df_cutoffs['Score'][0] = max_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Uc5CXEfyeSje"
      },
      "outputs": [],
      "source": [
        "# defining a function called 'n_approved' which assigns a value of 1 if a predicted probability\n",
        "def n_approved(p):\n",
        "    return np.where(df_actual_predicted_probs['y_hat_test_proba'] >= p, 1, 0).sum()\n",
        "\n",
        "# With the assumption that a given probability of being 'good' will be approved,\n",
        "# we obtain # of approved applications.\n",
        "df_cutoffs['N Approved'] = df_cutoffs['thresholds'].apply(n_approved)\n",
        "\n",
        "# Calculating # of rejected applications for each threshold.\n",
        "df_cutoffs['N Rejected'] = df_actual_predicted_probs['y_hat_test_proba'].shape[0] - df_cutoffs['N Approved']\n",
        "\n",
        "# Approval rate = the ratio of the apprv'd apps and all apps.\n",
        "df_cutoffs['Approval Rate'] = df_cutoffs['N Approved'] / df_actual_predicted_probs['y_hat_test_proba'].shape[0]\n",
        "\n",
        "# Rejection rate.\n",
        "df_cutoffs['Rejection Rate'] = 1 - df_cutoffs['Approval Rate']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HRDvDtOSeXhg",
        "outputId": "79e394a8-2838-455c-f806-503e03cdcc61"
      },
      "outputs": [],
      "source": [
        "# displaying the df with cutoffs form l/ w ind 5600 to l/ w ind 5650.\n",
        "df_cutoffs.iloc[5600: 5650, ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0DGa9zhp9jI"
      },
      "source": [
        "If the cutoff score is 495, half of the applications will be accepted for credit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_CHM_mm3eY40",
        "outputId": "c9e03a4e-d443-41c2-86e2-ba60215621d5"
      },
      "outputs": [],
      "source": [
        "df_cutoffs.iloc[1000: 2000, ]\n",
        "# Here we display the dataframe with cutoffs form line with index 1000 to line with index 2000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYSj4xE2qUmk"
      },
      "source": [
        "If the cutoff score is 558, only about 15% of the applications will be accepted for credit."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kr4hjR3nWYbJ"
      },
      "source": [
        "--- END OF NOTEBOOK ---  \n",
        "#END"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JAk-mSJh9HZS",
        "X9m2L_-LUfnp",
        "8j5oV2VwFmHn"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
